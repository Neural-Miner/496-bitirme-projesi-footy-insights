{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc1c829-0fe6-482f-b0c1-445819749eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: timm in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (1.0.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from timm) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from timm) (0.21.0+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Using cached transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.21.1 transformers-4.50.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010ea3b9-05e0-41a2-a8bf-0fa8cb5dce2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.transforms.functional_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReal-ESRGAN\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Real-ESRGAN klasörünü yol olarak ekle\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrrdbnet_arch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RRDBNet\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrealesrgan\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RealESRGANer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# === Adım 0: Yol ayarları ===\u001b[39;00m\n\u001b[0;32m     20\u001b[0m image_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEkran görüntüsü 2025-03-31 152531.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\uysal\\real-esrgan\\realesrgan\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\uysal\\real-esrgan\\realesrgan\\data\\__init__.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m dataset_filenames \u001b[38;5;241m=\u001b[39m [osp\u001b[38;5;241m.\u001b[39msplitext(osp\u001b[38;5;241m.\u001b[39mbasename(v))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m scandir(data_folder) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dataset.py\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# import all the dataset modules\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m _dataset_modules \u001b[38;5;241m=\u001b[39m [importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrealesrgan.data.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m dataset_filenames]\n",
      "File \u001b[1;32mc:\\users\\uysal\\real-esrgan\\realesrgan\\data\\__init__.py:10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m dataset_filenames \u001b[38;5;241m=\u001b[39m [osp\u001b[38;5;241m.\u001b[39msplitext(osp\u001b[38;5;241m.\u001b[39mbasename(v))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m scandir(data_folder) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dataset.py\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# import all the dataset modules\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m _dataset_modules \u001b[38;5;241m=\u001b[39m [\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrealesrgan.data.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m dataset_filenames]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\uysal\\real-esrgan\\realesrgan\\data\\realesrgan_dataset.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdegradations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m circular_lowpass_kernel, random_mixed_kernels\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m augment\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileClient, get_root_logger, imfrombytes, img2tensor\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\basicsr\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# https://github.com/xinntao/BasicSR\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\basicsr\\data\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m dataset_filenames \u001b[38;5;241m=\u001b[39m [osp\u001b[38;5;241m.\u001b[39msplitext(osp\u001b[38;5;241m.\u001b[39mbasename(v))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m scandir(data_folder) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dataset.py\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# import all the dataset modules\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m _dataset_modules \u001b[38;5;241m=\u001b[39m [importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasicsr.data.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m dataset_filenames]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_dataset\u001b[39m(dataset_opt):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build dataset from options.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m            type (str): Dataset type.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\basicsr\\data\\__init__.py:22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m dataset_filenames \u001b[38;5;241m=\u001b[39m [osp\u001b[38;5;241m.\u001b[39msplitext(osp\u001b[38;5;241m.\u001b[39mbasename(v))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m scandir(data_folder) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dataset.py\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# import all the dataset modules\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m _dataset_modules \u001b[38;5;241m=\u001b[39m [\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbasicsr.data.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m dataset_filenames]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_dataset\u001b[39m(dataset_opt):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build dataset from options.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m            type (str): Dataset type.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\basicsr\\data\\realesrgan_dataset.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data \u001b[38;5;28;01mas\u001b[39;00m data\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdegradations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m circular_lowpass_kernel, random_mixed_kernels\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m augment\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbasicsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileClient, get_root_logger, imfrombytes, img2tensor\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\basicsr\\data\\degradations.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m special\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multivariate_normal\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rgb_to_grayscale\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------- #\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# --------------------------- blur kernels --------------------------- #\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------- #\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# --------------------------- util functions --------------------------- #\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msigma_matrix2\u001b[39m(sig_x, sig_y, theta):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.transforms.functional_tensor'"
     ]
    }
   ],
   "source": [
    "# Notebook: jersey_detection.ipynb\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import AutoProcessor, VisionEncoderDecoderModel\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"Real-ESRGAN\")  # Real-ESRGAN klasörünü yol olarak ekle\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "model_path = \"Real-ESRGAN/weights/RealESRGAN_x4plus.pth\"\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25  # Tespit güven eşiği\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Torso Crop ===\n",
    "crops = []\n",
    "boxes = []\n",
    "for det in preds:\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y1 = y1 + int((y2 - y1) * 0.4)\n",
    "    crop = img[torso_y1:y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crops.append(crop)\n",
    "        boxes.append((x1, torso_y1, x2, y2))\n",
    "\n",
    "# === Adım 3: Super Resolution (Real-ESRGAN) ===\n",
    "model_rrdb = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
    "                     num_block=23, num_grow_ch=32, scale=4)\n",
    "upscaler = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path=model_path,\n",
    "    model=model_rrdb,\n",
    "    tile=0,\n",
    "    tile_pad=10,\n",
    "    pre_pad=0,\n",
    "    half=True,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "sr_crops = []\n",
    "for crop in crops:\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)).convert(\"RGB\")\n",
    "    output, _ = upscaler.enhance(np.array(img_pil), outscale=1)\n",
    "    sr_crop = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    sr_crops.append(sr_crop)\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR, Tesseract, PARSeq ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "parseq_model = VisionEncoderDecoderModel.from_pretrained(\"impira/layoutlm-parseq\")\n",
    "parseq_processor = AutoProcessor.from_pretrained(\"impira/layoutlm-parseq\")\n",
    "parseq_model.eval()\n",
    "\n",
    "ocr_results = []\n",
    "transform = T.Compose([\n",
    "    T.Resize((384, 384)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def run_parseq(img_crop):\n",
    "    pil = Image.fromarray(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)).convert(\"RGB\")\n",
    "    inputs = parseq_processor(images=pil, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = parseq_model.generate(**inputs, max_length=4)\n",
    "    text = parseq_processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return text\n",
    "\n",
    "for crop in sr_crops:\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    parseq_text = run_parseq(crop)\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text, parseq_text.strip()]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti (Super Resolution Dahil)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b026af4-2307-4cb5-bf57-8b1679f91895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: numpy in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: torch==2.6.0+cu118 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torchvision) (2.6.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0+cu118->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from jinja2->torch==2.6.0+cu118->torchvision) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163c9c05-e3ee-4da9-bf4e-1eae6185a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to weights\\yolov5s.pt...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14.1M/14.1M [00:01<00:00, 10.3MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Devam etmek için ENTER'a basın... \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "impira/layoutlm-parseq is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/impira/layoutlm-parseq/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1593\u001b[0m ):\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    287\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    288\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m     )\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67eaadf1-2c5ac0192781252b1425f2d5;97dab53b-1c84-4468-a72a-e915155ca5bf)\n\nRepository Not Found for url: https://huggingface.co/impira/layoutlm-parseq/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# === Adım 4: OCR - EasyOCR, Tesseract, PARSeq ===\u001b[39;00m\n\u001b[0;32m     52\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m], gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 53\u001b[0m parseq_model \u001b[38;5;241m=\u001b[39m \u001b[43mVisionEncoderDecoderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimpira/layoutlm-parseq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m parseq_processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpira/layoutlm-parseq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m parseq_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py:378\u001b[0m, in \u001b[0;36mVisionEncoderDecoderModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    372\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast initialization is currently not supported for VisionEncoderDecoderModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to slow initialization...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    376\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fast_init\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\modeling_utils.py:272\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\modeling_utils.py:4134\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   4133\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m-> 4134\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4143\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4144\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4145\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4146\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4148\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   4149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\transformers\\utils\\hub.py:456\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    457\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: impira/layoutlm-parseq is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# Notebook: jersey_detection.ipynb\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import AutoProcessor, VisionEncoderDecoderModel\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Torso Crop ve PNG olarak kaydet ===\n",
    "boxes = []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y1 = y1 + int((y2 - y1) * 0.4)\n",
    "    crop = img[torso_y1:y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, torso_y1, x2, y2))\n",
    "\n",
    "# === Adım 3: Super Resolution dışarıda çalıştırılmalı ===\n",
    "print(\"🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\")\n",
    "input(\"Devam etmek için ENTER'a basın...\")\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR, Tesseract, PARSeq ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "parseq_model = VisionEncoderDecoderModel.from_pretrained(\"impira/layoutlm-parseq\")\n",
    "parseq_processor = AutoProcessor.from_pretrained(\"impira/layoutlm-parseq\")\n",
    "parseq_model.eval()\n",
    "\n",
    "ocr_results = []\n",
    "\n",
    "def run_parseq(img_crop):\n",
    "    pil = Image.fromarray(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)).convert(\"RGB\")\n",
    "    inputs = parseq_processor(images=pil, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = parseq_model.generate(**inputs, max_length=4)\n",
    "    text = parseq_processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return text\n",
    "\n",
    "# OCR için netleştirilmiş kırpılmış görselleri oku\n",
    "for i, box in enumerate(boxes):\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    parseq_text = run_parseq(crop)\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text, parseq_text.strip()]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti (Netleştirilmiş)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a4983a-1c49-4fb3-83b9-479c1a4616b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Devam etmek için ENTER'a basın... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çıktı kaydedildi: output\\results_frame1.jpg\n"
     ]
    }
   ],
   "source": [
    "# Notebook: jersey_detection.ipynb\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Torso Crop ve PNG olarak kaydet ===\n",
    "boxes = []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y1 = y1 + int((y2 - y1) * 0.4)\n",
    "    crop = img[torso_y1:y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, torso_y1, x2, y2))\n",
    "\n",
    "# === Adım 3: Super Resolution dışarıda çalıştırılmalı ===\n",
    "print(\"🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\")\n",
    "input(\"Devam etmek için ENTER'a basın...\")\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR ve Tesseract ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results = []\n",
    "\n",
    "# OCR için netleştirilmiş kırpılmış görselleri oku\n",
    "for i, box in enumerate(boxes):\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti (Netleştirilmiş)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a4798e-43c1-407b-aa67-243e3086e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "WARNING  NMS time limit 0.550s exceeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Devam etmek için ENTER'a basın... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çıktı kaydedildi: output\\results_frame2.jpg\n"
     ]
    }
   ],
   "source": [
    "# Notebook: jersey_detection.ipynb\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "output_path = Path(\"output/results_frame2.jpg\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Üst Gövde Crop ve PNG olarak kaydet ===\n",
    "boxes = []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y2 = y1 + int((y2 - y1) * 0.6)  # Üst %60'lık bölüm\n",
    "    crop = img[y1:torso_y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, y1, x2, torso_y2))\n",
    "\n",
    "# === Adım 3: Super Resolution dışarıda çalıştırılmalı ===\n",
    "print(\"🔁 Lütfen 'crops/' klasöründeki görselleri Real-ESRGAN ile netleştirip 'sr_crops/' klasörüne yazın.\")\n",
    "input(\"Devam etmek için ENTER'a basın...\")\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR ve Tesseract ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results = []\n",
    "\n",
    "# OCR için netleştirilmiş kırpılmış görselleri oku\n",
    "for i, box in enumerate(boxes):\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti (Üst Gövde Crop)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7278d7e-85bc-4014-b187-651f24ea6319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'Real-ESRGAN/inference_realesrgan.py', '-n', 'RealESRGAN_x4plus', '-i', 'crops', '-o', 'sr_crops'], returncode=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e74d0d-b8d3-45e3-b390-b9a077e68049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\Users\\uysal\\inference_realesrgan.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python inference_realesrgan.py -n RealESRGAN_x4plus -i crops -o sr_crops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c814443-f8af-43a5-8e4f-b0513d022cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Real-ESRGAN ile netleştirme başlatılıyor...\n",
      "✅ Netleştirme tamamlandı. OCR işlemine geçiliyor...\n",
      "Çıktı kaydedildi: output\\results_frame1.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "crop_dir = Path(\"crops\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Üst Gövde Crop ve PNG olarak kaydet ===\n",
    "boxes = []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y2 = y1 + int((y2 - y1) * 0.6)  # Üst %60'lık bölüm\n",
    "    crop = img[y1:torso_y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, y1, x2, torso_y2))\n",
    "\n",
    "# === Adım 3: Super Resolution - Notebook içinden çalıştırılıyor ===\n",
    "import subprocess\n",
    "\n",
    "print(\"🔁 Real-ESRGAN ile netleştirme başlatılıyor...\")\n",
    "subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\"\n",
    "])\n",
    "print(\"✅ Netleştirme tamamlandı. OCR işlemine geçiliyor...\")\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR ve Tesseract ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results = []\n",
    "\n",
    "# OCR için netleştirilmiş kırpılmış görselleri oku\n",
    "for i, box in enumerate(boxes):\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti (Üst Gövde Crop)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d8e753f-c091-43be-a2d2-0a7c2da9dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Real-ESRGAN ile netleştirme başlatılıyor...\n",
      "✅ Netleştirme tamamlandı. OCR işlemine geçiliyor...\n",
      "📸 Çıktı kaydedildi: output\\results_frame1.jpg\n",
      "\n",
      "🔍 OCR Sonuçları:\n",
      "Crop 0: ?\n",
      "Crop 1: ?\n",
      "Crop 2: ?\n",
      "Crop 3: ?\n",
      "Crop 4: ?\n",
      "Crop 5: ?\n",
      "Crop 6: ?\n",
      "Crop 7: ?\n",
      "Crop 8: ?\n",
      "Crop 9: ?\n",
      "Crop 10: ?\n",
      "Crop 11: ?\n",
      "Crop 12: ?\n",
      "Crop 13: ?\n",
      "Crop 14: ?\n",
      "Crop 15: ?\n",
      "Crop 16: ?\n",
      "Crop 17: ?\n",
      "Crop 18: ?\n",
      "Crop 19: ?\n",
      "Crop 20: ?\n",
      "Crop 21: ?\n",
      "Crop 22: ?\n",
      "Crop 23: ?\n",
      "📄 OCR sonuçları CSV olarak kaydedildi: output/ocr_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# === Adım 0: Yol ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Adım 1: YOLOv5 ile oyuncu tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Adım 2: Üst Gövde Crop ve PNG olarak kaydet ===\n",
    "boxes = []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "    torso_y2 = y1 + int((y2 - y1) * 0.6)  # Üst %60'lık bölüm\n",
    "    crop = img[y1:torso_y2, x1:x2]\n",
    "    if crop.size > 0:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, y1, x2, torso_y2))\n",
    "\n",
    "# === Adım 3: Super Resolution - Notebook içinden çalıştırılıyor ===\n",
    "print(\"🔁 Real-ESRGAN ile netleştirme başlatılıyor...\")\n",
    "subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\",\n",
    "    \"--fp32\"  # GPU varsa yine kullanılır, CPU fallback için gerekli\n",
    "])\n",
    "print(\"✅ Netleştirme tamamlandı. OCR işlemine geçiliyor...\")\n",
    "\n",
    "# === Adım 4: OCR - EasyOCR ve Tesseract ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results = []\n",
    "\n",
    "for i, box in enumerate(boxes):\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text = easy_out[0][1] if easy_out else \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "    tess_text = tess_text.strip()\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text]\n",
    "    digits = [c for c in candidates if c.isdigit()]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "\n",
    "# === Adım 5: Sonuçları görselleştirme ===\n",
    "for box, number in zip(boxes, ocr_results):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"📸 Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "# === OCR Sonuçlarını yazdır ve CSV olarak kaydet ===\n",
    "print(\"\\n🔍 OCR Sonuçları:\")\n",
    "for i, number in enumerate(ocr_results):\n",
    "    print(f\"Crop {i}: {number}\")\n",
    "\n",
    "ocr_df = pd.DataFrame({\n",
    "    \"crop_file\": [f\"crop_{i}.png\" for i in range(len(ocr_results))],\n",
    "    \"predicted_number\": ocr_results\n",
    "})\n",
    "ocr_df.to_csv(\"output/ocr_results.csv\", index=False)\n",
    "print(\"📄 OCR sonuçları CSV olarak kaydedildi: output/ocr_results.csv\")\n",
    "\n",
    "# === Son görseli göster ===\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bfedd5d-419a-48aa-ad64-299bfcab0cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": false,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop 0: blur=161.45, contrast=41.56\n",
      "Crop 1: blur=172.76, contrast=43.02\n",
      "Crop 2: blur=186.59, contrast=36.00\n",
      "Crop 3: blur=190.06, contrast=31.45\n",
      "Crop 4: blur=193.84, contrast=42.32\n",
      "Crop 5: blur=140.03, contrast=33.31\n",
      "Crop 6: blur=259.64, contrast=46.25\n",
      "Crop 7: blur=376.03, contrast=37.57\n",
      "Crop 8: blur=202.15, contrast=34.23\n",
      "Crop 9: blur=304.95, contrast=24.38\n",
      "Crop 10: blur=537.24, contrast=48.64\n",
      "Crop 11: blur=385.01, contrast=44.56\n",
      "Crop 12: blur=413.78, contrast=44.87\n",
      "Crop 13: blur=12863.94, contrast=62.26\n",
      "Crop 14: blur=323.14, contrast=43.50\n",
      "Crop 15: blur=265.58, contrast=40.65\n",
      "Crop 16: blur=238.08, contrast=46.78\n",
      "Crop 17: blur=30715.64, contrast=65.45\n",
      "Crop 18: blur=34926.11, contrast=68.17\n",
      "Crop 19: blur=508.76, contrast=50.82\n",
      "Crop 20: blur=382.73, contrast=36.18\n",
      "Crop 21: blur=1254.65, contrast=52.06\n",
      "Crop 22: blur=375.23, contrast=36.04\n",
      "Crop 23: blur=505.84, contrast=40.28\n",
      "🔁 Real-ESRGAN başlatılıyor...\n",
      "✅ Netleştirme tamamlandı. OCR başlıyor...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m tess_text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(crop_pil, config\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--psm 8 -c tessedit_char_whitelist=0123456789\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# PARSeq\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m parseq_text \u001b[38;5;241m=\u001b[39m \u001b[43mrun_parseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_pil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Adaylar\u001b[39;00m\n\u001b[0;32m    122\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [easy_text\u001b[38;5;241m.\u001b[39mstrip(), tess_text, parseq_text\u001b[38;5;241m.\u001b[39mstrip()]\n",
      "Cell \u001b[1;32mIn[38], line 87\u001b[0m, in \u001b[0;36mrun_parseq\u001b[1;34m(img_pil)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_parseq\u001b[39m(img_pil):\n\u001b[1;32m---> 87\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mparseq_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_pil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     89\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m parseq_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2881\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2879\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2883\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2884\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import VisionEncoderDecoderModel, AutoProcessor\n",
    "\n",
    "# === Yol Ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === PARSeq OCR Yükleniyor ===\n",
    "parseq_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
    "parseq_processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "parseq_model.to(device).eval()\n",
    "\n",
    "# === Kontrast Artırma Fonksiyonu ===\n",
    "def enhance_contrast(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# === YOLOv5 ile Oyuncu Tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Crop (Sırt Bölgesi) + Kontrast + Filtreleme ===\n",
    "boxes, valid_crop_indices = [], []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, _, _ = map(int, det[:6])\n",
    "    torso_y1 = y1 + int((y2 - y1) * 0.4)\n",
    "    torso_y2 = y1 + int((y2 - y1) * 0.9)\n",
    "    crop = img[torso_y1:torso_y2, x1:x2]\n",
    "\n",
    "    if crop.size == 0:\n",
    "        continue\n",
    "\n",
    "    crop = enhance_contrast(crop)\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    contrast = gray.std()\n",
    "    print(f\"Crop {i}: blur={blur:.2f}, contrast={contrast:.2f}\")\n",
    "\n",
    "    if blur > 20 and contrast > 20:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, torso_y1, x2, torso_y2))\n",
    "        valid_crop_indices.append(i)\n",
    "\n",
    "# === Real-ESRGAN ile Netleştirme ===\n",
    "print(\"🔁 Real-ESRGAN başlatılıyor...\")\n",
    "subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\",\n",
    "    \"--fp32\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"✅ Netleştirme tamamlandı. OCR başlıyor...\")\n",
    "\n",
    "# === OCR Fonksiyonu (PARSeq) ===\n",
    "def run_parseq(img_pil):\n",
    "    inputs = parseq_processor(images=img_pil, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = parseq_model.generate(**inputs)\n",
    "    return parseq_processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# === OCR İşlemi: EasyOCR + Tesseract + PARSeq ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results, ocr_logs = [], []\n",
    "\n",
    "for j, i in enumerate(valid_crop_indices):\n",
    "    box = boxes[j]\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}_out.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        ocr_logs.append((i, \"?\", 0.0, \"missing\", \"missing\"))\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text, easy_conf = \"\", 0.0\n",
    "    if easy_out:\n",
    "        easy_text = easy_out[0][1]\n",
    "        easy_conf = easy_out[0][2]\n",
    "        if easy_conf < 0.4: easy_text = \"\"\n",
    "\n",
    "    # Tesseract\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 8 -c tessedit_char_whitelist=0123456789').strip()\n",
    "\n",
    "    # PARSeq\n",
    "    parseq_text = run_parseq(crop_pil)\n",
    "\n",
    "    # Adaylar\n",
    "    candidates = [easy_text.strip(), tess_text, parseq_text.strip()]\n",
    "    digits = [re.findall(r'\\d+', c) for c in candidates if c]\n",
    "    digits = [d[0] for d in digits if d]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "    ocr_logs.append((i, final_text, easy_conf, tess_text, parseq_text))\n",
    "\n",
    "# === Orijinal Görsel Üzerine Yaz ===\n",
    "for (x1, y1, x2, y2), number in zip(boxes, ocr_results):\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"📸 Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "# === OCR Detay Logları ve CSV ===\n",
    "print(\"\\n🔍 OCR Sonuçları (Detaylı):\")\n",
    "for i, number, conf, tess, parseq in ocr_logs:\n",
    "    print(f\"Crop {i}: Tahmin='{number}' | EasyOCR_conf={conf:.2f} | Tesseract='{tess}' | PARSeq='{parseq}'\")\n",
    "\n",
    "ocr_df = pd.DataFrame({\n",
    "    \"crop_file\": [f\"crop_{i}.png\" for i in valid_crop_indices],\n",
    "    \"predicted_number\": ocr_results\n",
    "})\n",
    "ocr_df.to_csv(\"output/ocr_results.csv\", index=False)\n",
    "print(\"📄 OCR sonuçları CSV olarak kaydedildi: output/ocr_results.csv\")\n",
    "\n",
    "# === Görseli Göster ===\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e78a1372-6164-4fd2-b096-9a733ea76dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0\n",
      "Uninstalling torch-2.6.0:\n",
      "  Successfully uninstalled torch-2.6.0\n",
      "Found existing installation: torchvision 0.21.0\n",
      "Uninstalling torchvision-0.21.0:\n",
      "  Successfully uninstalled torchvision-0.21.0\n",
      "Found existing installation: torchaudio 2.6.0+cu118\n",
      "Uninstalling torchaudio-2.6.0+cu118:\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6528c847-487d-4bce-974e-326c3d081ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51e5081f-3b25-46cf-b10a-b5a4c2e4cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting torch==2.6.0 (from torchvision)\n",
      "  Using cached torch-2.6.0-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.1.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting filelock (from torch==2.6.0->torchvision)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch==2.6.0->torchvision)\n",
      "  Using cached typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch==2.6.0->torchvision)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch==2.6.0->torchvision)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.6.0->torchvision)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0->torchvision)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0->torchvision)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0->torchvision)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torchvision-0.21.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.1 MB/s eta 0:00:00\n",
      "Using cached torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached pillow-11.1.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Using cached typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu118\n",
      "    Uninstalling torch-2.6.0+cu118:\n",
      "      Successfully uninstalled torch-2.6.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu118\n",
      "    Uninstalling torchvision-0.21.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu118\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 pillow-11.1.0 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 typing-extensions-4.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\Lib\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu118 requires torch==2.6.0+cu118, but you have torch 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b9d23-92bc-45aa-bf2a-80d67373a47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "262a880e-5e1b-4516-b53b-0ec1977cf5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": false,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop 0: blur=161.45, contrast=41.56\n",
      "Crop 1: blur=172.76, contrast=43.02\n",
      "Crop 2: blur=186.59, contrast=36.00\n",
      "Crop 3: blur=190.06, contrast=31.45\n",
      "Crop 4: blur=193.84, contrast=42.32\n",
      "Crop 5: blur=140.03, contrast=33.31\n",
      "Crop 6: blur=259.64, contrast=46.25\n",
      "Crop 7: blur=376.03, contrast=37.57\n",
      "Crop 8: blur=202.15, contrast=34.23\n",
      "Crop 9: blur=304.95, contrast=24.38\n",
      "Crop 10: blur=537.24, contrast=48.64\n",
      "Crop 11: blur=385.01, contrast=44.56\n",
      "Crop 12: blur=413.78, contrast=44.87\n",
      "Crop 13: blur=12863.94, contrast=62.26\n",
      "Crop 14: blur=323.14, contrast=43.50\n",
      "Crop 15: blur=265.58, contrast=40.65\n",
      "Crop 16: blur=238.08, contrast=46.78\n",
      "Crop 17: blur=30715.64, contrast=65.45\n",
      "Crop 18: blur=34926.11, contrast=68.17\n",
      "Crop 19: blur=508.76, contrast=50.82\n",
      "Crop 20: blur=382.73, contrast=36.18\n",
      "Crop 21: blur=1254.65, contrast=52.06\n",
      "Crop 22: blur=375.23, contrast=36.04\n",
      "Crop 23: blur=505.84, contrast=40.28\n",
      "🔁 Real-ESRGAN başlatılıyor...\n",
      "✅ Netleştirme tamamlandı. OCR başlıyor...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m easy_conf \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.4\u001b[39m: easy_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m tess_text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(crop_pil, config\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--psm 8 -c tessedit_char_whitelist=0123456789\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m--> 114\u001b[0m parseq_text \u001b[38;5;241m=\u001b[39m \u001b[43mrun_parseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_pil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [easy_text\u001b[38;5;241m.\u001b[39mstrip(), tess_text, parseq_text\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m    117\u001b[0m digits \u001b[38;5;241m=\u001b[39m [re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m, c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates \u001b[38;5;28;01mif\u001b[39;00m c]\n",
      "Cell \u001b[1;32mIn[35], line 86\u001b[0m, in \u001b[0;36mrun_parseq\u001b[1;34m(img_pil)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_parseq\u001b[39m(img_pil):\n\u001b[1;32m---> 86\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mparseq_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_pil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(parseq_model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     88\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m parseq_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2881\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2879\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2883\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2884\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import VisionEncoderDecoderModel, AutoProcessor\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# === Yol Ayarları ===\n",
    "image_path = Path(\"Ekran görüntüsü 2025-03-31 152531.png\")\n",
    "crop_dir = Path(\"crops\")\n",
    "sr_crop_dir = Path(\"sr_crops\")\n",
    "output_path = Path(\"output/results_frame1.jpg\")\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "yolo_weights = \"weights/yolov5s.pt\"\n",
    "\n",
    "crop_dir.mkdir(exist_ok=True)\n",
    "sr_crop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === PARSeq Yükle ===\n",
    "parseq_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
    "parseq_processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
    "parseq_model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Super Resolution için kontrastı artırma ===\n",
    "def enhance_contrast(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# === YOLOv5 ile Oyuncu Tespiti ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=yolo_weights)\n",
    "model.conf = 0.25\n",
    "\n",
    "img = cv2.imread(str(image_path))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(img_rgb)\n",
    "preds = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "# === Üst Gövde Crop & Kontrast Artırımı ===\n",
    "boxes, valid_crop_indices = [], []\n",
    "for i, det in enumerate(preds):\n",
    "    x1, y1, x2, y2, _, _ = map(int, det[:6])\n",
    "    torso_y1 = y1 + int((y2 - y1) * 0.4)\n",
    "    torso_y2 = y1 + int((y2 - y1) * 0.9)\n",
    "    crop = img[torso_y1:torso_y2, x1:x2]\n",
    "    \n",
    "    if crop.size == 0: continue\n",
    "    crop = enhance_contrast(crop)\n",
    "\n",
    "    blur = cv2.Laplacian(cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()\n",
    "    contrast = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY).std()\n",
    "    print(f\"Crop {i}: blur={blur:.2f}, contrast={contrast:.2f}\")\n",
    "\n",
    "    if blur > 20 and contrast > 20:\n",
    "        crop_path = crop_dir / f\"crop_{i}.png\"\n",
    "        cv2.imwrite(str(crop_path), crop)\n",
    "        boxes.append((x1, torso_y1, x2, torso_y2))\n",
    "        valid_crop_indices.append(i)\n",
    "\n",
    "# === Real-ESRGAN ile Netleştirme ===\n",
    "print(\"🔁 Real-ESRGAN başlatılıyor...\")\n",
    "subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\",\n",
    "    \"--fp32\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"✅ Netleştirme tamamlandı. OCR başlıyor...\")\n",
    "\n",
    "# === OCR Fonksiyonu (PARSeq) ===\n",
    "def run_parseq(img_pil):\n",
    "    inputs = parseq_processor(images=img_pil, return_tensors=\"pt\").to(parseq_model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = parseq_model.generate(**inputs)\n",
    "    return parseq_processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# === OCR İşlemi ===\n",
    "reader = easyocr.Reader([\"en\"], gpu=True)\n",
    "ocr_results, ocr_logs = [], []\n",
    "\n",
    "for j, i in enumerate(valid_crop_indices):\n",
    "    box = boxes[j]\n",
    "    sr_crop_path = sr_crop_dir / f\"crop_{i}_out.png\"\n",
    "    if not sr_crop_path.exists():\n",
    "        ocr_results.append(\"?\")\n",
    "        ocr_logs.append((i, \"?\", 0.0, \"missing\", \"missing\"))\n",
    "        continue\n",
    "\n",
    "    crop = cv2.imread(str(sr_crop_path))\n",
    "    crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    easy_out = reader.readtext(np.array(crop))\n",
    "    easy_text, easy_conf = \"\", 0.0\n",
    "    if easy_out:\n",
    "        easy_text = easy_out[0][1]\n",
    "        easy_conf = easy_out[0][2]\n",
    "        if easy_conf < 0.4: easy_text = \"\"\n",
    "\n",
    "    tess_text = pytesseract.image_to_string(crop_pil, config='--psm 8 -c tessedit_char_whitelist=0123456789').strip()\n",
    "    parseq_text = run_parseq(crop_pil)\n",
    "\n",
    "    candidates = [easy_text.strip(), tess_text, parseq_text.strip()]\n",
    "    digits = [re.findall(r'\\d+', c) for c in candidates if c]\n",
    "    digits = [d[0] for d in digits if d]\n",
    "    final_text = digits[0] if digits else \"?\"\n",
    "\n",
    "    ocr_results.append(final_text)\n",
    "    ocr_logs.append((i, final_text, easy_conf, tess_text, parseq_text))\n",
    "\n",
    "# === Görsel Üzerine Yaz ===\n",
    "for (x1, y1, x2, y2), number in zip(boxes, ocr_results):\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(str(output_path), img)\n",
    "print(f\"📸 Çıktı kaydedildi: {output_path}\")\n",
    "\n",
    "# === OCR Sonuçları Log ve CSV ===\n",
    "print(\"\\n🔍 OCR Sonuçları (Detaylı):\")\n",
    "for i, number, conf, tess, parseq in ocr_logs:\n",
    "    print(f\"Crop {i}: Tahmin='{number}' | EasyOCR_conf={conf:.2f} | Tesseract='{tess}' | PARSeq='{parseq}'\")\n",
    "\n",
    "ocr_df = pd.DataFrame({\n",
    "    \"crop_file\": [f\"crop_{i}.png\" for i in valid_crop_indices],\n",
    "    \"predicted_number\": ocr_results\n",
    "})\n",
    "ocr_df.to_csv(\"output/ocr_results.csv\", index=False)\n",
    "\n",
    "# === Görseli Göster ===\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Forma Numarası Tespiti\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90d865cc-25e4-49e8-8981-548530b62cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n",
      "0.21.0+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63591536-ed31-4482-842a-febb9d5eafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crops\\\\crop_0.png', 'crops\\\\crop_1.png', 'crops\\\\crop_10.png', 'crops\\\\crop_11.png', 'crops\\\\crop_12.png', 'crops\\\\crop_13.png', 'crops\\\\crop_14.png', 'crops\\\\crop_15.png', 'crops\\\\crop_16.png', 'crops\\\\crop_17.png', 'crops\\\\crop_18.png', 'crops\\\\crop_19.png', 'crops\\\\crop_2.png', 'crops\\\\crop_20.png', 'crops\\\\crop_21.png', 'crops\\\\crop_22.png', 'crops\\\\crop_23.png', 'crops\\\\crop_3.png', 'crops\\\\crop_4.png', 'crops\\\\crop_5.png', 'crops\\\\crop_6.png', 'crops\\\\crop_7.png', 'crops\\\\crop_8.png', 'crops\\\\crop_9.png']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "print(glob(\"crops/*.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06c334f-6684-4ff7-ae0e-86d6c7f840ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0 crop_0\n",
      "Testing 1 crop_1\n",
      "Testing 2 crop_10\n",
      "Testing 3 crop_11\n",
      "Testing 4 crop_12\n",
      "Testing 5 crop_13\n",
      "Testing 6 crop_14\n",
      "Testing 7 crop_15\n",
      "Testing 8 crop_16\n",
      "Testing 9 crop_17\n",
      "Testing 10 crop_18\n",
      "Testing 11 crop_19\n",
      "Testing 12 crop_2\n",
      "Testing 13 crop_20\n",
      "Testing 14 crop_21\n",
      "Testing 15 crop_22\n",
      "Testing 16 crop_23\n",
      "Testing 17 crop_3\n",
      "Testing 18 crop_4\n",
      "Testing 19 crop_5\n",
      "Testing 20 crop_6\n",
      "Testing 21 crop_7\n",
      "Testing 22 crop_8\n",
      "Testing 23 crop_9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run([\n",
    "    \"python\", \"Real-ESRGAN/inference_realesrgan.py\",\n",
    "    \"-n\", \"RealESRGAN_x4plus\",\n",
    "    \"-i\", \"crops\",\n",
    "    \"-o\", \"sr_crops\",\n",
    "    \"--fp32\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b3e37-5dfb-4742-a9ec-f7a12b32ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA kullanılabilir mi? 👉\", torch.cuda.is_available())\n",
    "print(\"Aktif cihaz:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Yok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6f7011-2b59-493e-8b52-43b7c435bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting basicsr\n",
      "  Using cached basicsr-1.4.2-py3-none-any.whl\n",
      "Collecting addict (from basicsr)\n",
      "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting future (from basicsr)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: lmdb in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (1.23.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (11.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (2.32.3)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from basicsr) (0.24.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (1.13.1)\n",
      "Collecting tb-nightly (from basicsr)\n",
      "  Downloading tb_nightly-2.20.0a20250401-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr) (4.67.1)\n",
      "Collecting yapf (from basicsr)\n",
      "  Using cached yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->basicsr) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from sympy==1.13.1->torch>=1.7->basicsr) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr) (2025.1.31)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image->basicsr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from scikit-image->basicsr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from scikit-image->basicsr) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image->basicsr) (0.4)\n",
      "Collecting absl-py>=0.4 (from tb-nightly->basicsr)\n",
      "  Using cached absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio>=1.48.2 (from tb-nightly->basicsr)\n",
      "  Using cached grpcio-1.71.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tb-nightly->basicsr)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tb-nightly->basicsr)\n",
      "  Using cached protobuf-6.30.2-cp39-cp39-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr) (75.8.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tb-nightly->basicsr)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tb-nightly->basicsr)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tqdm->basicsr) (0.4.6)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from yapf->basicsr) (3.10.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from yapf->basicsr) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from markdown>=2.6.8->tb-nightly->basicsr) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->basicsr) (3.21.0)\n",
      "Using cached addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading tb_nightly-2.20.0a20250401-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.5 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.7 MB/s eta 0:00:00\n",
      "Using cached yapf-0.43.0-py3-none-any.whl (256 kB)\n",
      "Using cached absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Using cached grpcio-1.71.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached protobuf-6.30.2-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: addict, yapf, werkzeug, tensorboard-data-server, protobuf, grpcio, future, absl-py, markdown, tb-nightly, basicsr\n",
      "Successfully installed absl-py-2.2.1 addict-2.4.0 basicsr-1.4.2 future-1.0.0 grpcio-1.71.0 markdown-3.7 protobuf-6.30.2 tb-nightly-2.20.0a20250401 tensorboard-data-server-0.7.2 werkzeug-3.1.3 yapf-0.43.0\n"
     ]
    }
   ],
   "source": [
    "!pip install basicsr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435aaba1-ab09-4aba-8966-f370b0b27c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: basicsr>=1.4.2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 1)) (1.4.2)\n",
      "Collecting facexlib>=0.2.5 (from -r Real-ESRGAN/requirements.txt (line 2))\n",
      "  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting gfpgan>=1.3.5 (from -r Real-ESRGAN/requirements.txt (line 3))\n",
      "  Using cached gfpgan-1.3.8-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 4)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 5)) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 7)) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 8)) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from -r Real-ESRGAN/requirements.txt (line 9)) (4.67.1)\n",
      "Requirement already satisfied: addict in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: future in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: lmdb in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (1.6.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (0.24.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: tb-nightly in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.20.0a20250401)\n",
      "Requirement already satisfied: yapf in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (0.43.0)\n",
      "Collecting filterpy (from facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2))\n",
      "  Using cached filterpy-1.4.5-py3-none-any.whl\n",
      "Collecting numba (from facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2))\n",
      "  Using cached numba-0.60.0-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from sympy==1.13.1->torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tqdm->-r Real-ESRGAN/requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (3.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from jinja2->torch>=1.7->-r Real-ESRGAN/requirements.txt (line 7)) (3.0.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2))\n",
      "  Using cached llvmlite-0.43.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from scikit-image->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from scikit-image->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\uysal\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (6.30.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (75.8.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from yapf->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from yapf->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from markdown>=2.6.8->tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r Real-ESRGAN/requirements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->basicsr>=1.4.2->-r Real-ESRGAN/requirements.txt (line 1)) (3.21.0)\n",
      "Using cached facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
      "Using cached gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
      "Using cached numba-0.60.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Using cached llvmlite-0.43.0-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Installing collected packages: llvmlite, numba, filterpy, facexlib, gfpgan\n",
      "Successfully installed facexlib-0.3.0 filterpy-1.4.5 gfpgan-1.3.8 llvmlite-0.43.0 numba-0.60.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r Real-ESRGAN/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "263698fe-fcc3-46b3-909f-d1085e195a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.14.1\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torchvision==0.14.1) (4.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torchvision==0.14.1) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torchvision==0.14.1) (2.32.3)\n",
      "Collecting torch==1.13.1 (from torchvision==0.14.1)\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from torchvision==0.14.1) (11.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->torchvision==0.14.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->torchvision==0.14.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages (from requests->torchvision==0.14.1) (2025.1.31)\n",
      "Downloading torchvision-0.14.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.5/1.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "   ---------------------------------------- 0.0/162.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/162.5 MB 3.0 MB/s eta 0:00:54\n",
      "   ---------------------------------------- 1.8/162.5 MB 4.0 MB/s eta 0:00:40\n",
      "    --------------------------------------- 3.7/162.5 MB 5.7 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 6.3/162.5 MB 7.3 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 8.7/162.5 MB 8.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 11.0/162.5 MB 8.6 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 12.8/162.5 MB 8.8 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 14.9/162.5 MB 8.7 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 17.0/162.5 MB 8.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 19.4/162.5 MB 9.0 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 20.4/162.5 MB 8.7 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 22.8/162.5 MB 8.8 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 25.2/162.5 MB 9.0 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 27.5/162.5 MB 9.1 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 29.9/162.5 MB 9.2 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 32.0/162.5 MB 9.3 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 33.8/162.5 MB 9.2 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 35.9/162.5 MB 9.3 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 38.5/162.5 MB 9.4 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 40.9/162.5 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 43.3/162.5 MB 9.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 45.9/162.5 MB 9.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 48.0/162.5 MB 9.7 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 50.3/162.5 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 52.2/162.5 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 54.5/162.5 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 56.4/162.5 MB 9.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 58.5/162.5 MB 9.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 60.3/162.5 MB 9.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 62.4/162.5 MB 9.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 63.4/162.5 MB 9.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 64.2/162.5 MB 9.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 65.0/162.5 MB 9.2 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 66.1/162.5 MB 9.1 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 66.8/162.5 MB 9.0 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 67.9/162.5 MB 8.8 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 68.7/162.5 MB 8.7 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 69.5/162.5 MB 8.6 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 70.3/162.5 MB 8.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 70.8/162.5 MB 8.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 71.3/162.5 MB 8.1 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 71.8/162.5 MB 8.0 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 72.4/162.5 MB 7.9 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 72.9/162.5 MB 7.7 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 73.4/162.5 MB 7.6 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 73.9/162.5 MB 7.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 74.4/162.5 MB 7.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 75.0/162.5 MB 7.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 75.8/162.5 MB 7.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 76.3/162.5 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 77.1/162.5 MB 7.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 77.6/162.5 MB 7.0 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 78.4/162.5 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 78.9/162.5 MB 6.8 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 79.7/162.5 MB 6.8 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 80.2/162.5 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 81.0/162.5 MB 6.7 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 81.8/162.5 MB 6.6 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 82.3/162.5 MB 6.5 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 82.8/162.5 MB 6.5 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 83.6/162.5 MB 6.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 84.1/162.5 MB 6.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 84.7/162.5 MB 6.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 85.2/162.5 MB 6.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 86.0/162.5 MB 6.2 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 86.8/162.5 MB 6.2 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 87.6/162.5 MB 6.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 88.3/162.5 MB 6.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 89.1/162.5 MB 6.1 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 89.9/162.5 MB 6.0 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 91.0/162.5 MB 6.0 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 91.8/162.5 MB 6.0 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 92.5/162.5 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 93.3/162.5 MB 5.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 94.1/162.5 MB 5.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.2/162.5 MB 5.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.9/162.5 MB 5.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 97.0/162.5 MB 5.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 97.8/162.5 MB 5.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 98.8/162.5 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 99.6/162.5 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 100.4/162.5 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 101.4/162.5 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 102.5/162.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 103.3/162.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 104.3/162.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 105.4/162.5 MB 5.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 106.2/162.5 MB 5.7 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 106.7/162.5 MB 5.7 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 107.2/162.5 MB 5.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 107.7/162.5 MB 5.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 108.3/162.5 MB 5.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 109.1/162.5 MB 5.5 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 110.4/162.5 MB 5.5 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 111.7/162.5 MB 5.5 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 113.2/162.5 MB 5.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 114.8/162.5 MB 5.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 116.4/162.5 MB 5.6 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 118.2/162.5 MB 5.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 120.3/162.5 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 122.2/162.5 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 124.3/162.5 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 126.4/162.5 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 128.7/162.5 MB 5.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 131.1/162.5 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 133.4/162.5 MB 5.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 135.8/162.5 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 137.9/162.5 MB 6.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 140.2/162.5 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 142.6/162.5 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 144.7/162.5 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 146.8/162.5 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 148.9/162.5 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 150.2/162.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 152.0/162.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 153.9/162.5 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 155.7/162.5 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 157.8/162.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.6/162.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  161.5/162.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  162.3/162.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  162.3/162.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  162.3/162.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.5/162.5 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu118\n",
      "    Uninstalling torch-2.6.0+cu118:\n",
      "      Successfully uninstalled torch-2.6.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu118\n",
      "    Uninstalling torchvision-0.21.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu118\n",
      "Successfully installed torch-1.13.1 torchvision-0.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\Lib\\site-packages\\~-rchvision'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 2.5.1 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchaudio 2.6.0+cu118 requires torch==2.6.0+cu118, but you have torch 1.13.1 which is incompatible.\n",
      "torchmetrics 1.7.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.14.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bd241f-85e4-4fee-a38a-b8aa6f4eac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_dir = \"number_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fonts = [cv2.FONT_HERSHEY_SIMPLEX, cv2.FONT_HERSHEY_COMPLEX, cv2.FONT_HERSHEY_DUPLEX]\n",
    "\n",
    "for num in range(1, 101):\n",
    "    label = str(num)\n",
    "    label_dir = os.path.join(output_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(100):  # Her sayıdan 100 tane üret\n",
    "        img = np.ones((64, 64, 3), dtype=np.uint8) * 255\n",
    "        font = np.random.choice(fonts)\n",
    "        font_scale = np.random.uniform(0.8, 1.2)\n",
    "        thickness = np.random.randint(1, 3)\n",
    "        text_size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "        text_x = (img.shape[1] - text_size[0]) // 2\n",
    "        text_y = (img.shape[0] + text_size[1]) // 2\n",
    "        cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
    "        cv2.imwrite(f\"{label_dir}/{i}.png\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be7dc65-fe15-4882-84f0-fee9920d66ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(100, activation='softmax')  # 100 sınıf için\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736caea-c006-45e0-9ad3-37cd890c4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    'number_dataset',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    'number_dataset',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0a7425-8a07-430b-87ac-76bdd7a88210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [39 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\requirements.py\", line 36, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\_parser.py\", line 62, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\_parser.py\", line 80, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\_parser.py\", line 124, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\_parser.py\", line 145, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\_tokenizer.py\", line 167, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\uysal\\AppData\\Local\\Temp\\pip-install-ezzplkhz\\tensorflow-gpu_c16f346c3b084758af623e4084864a03\\setup.py\", line 40, in <module>\n",
      "      setuptools.setup()\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\setuptools\\dist.py\", line 654, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\setuptools\\dist.py\", line 380, in _finalize_requires\n",
      "      self._normalize_requires()\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\setuptools\\dist.py\", line 398, in _normalize_requires\n",
      "      self.install_requires = list_(map(str, _reqs.parse(install_requires)))\n",
      "    File \"C:\\Users\\uysal\\anaconda3\\envs\\jersey-env-2\\lib\\site-packages\\packaging\\requirements.py\", line 38, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e1e23-7545-400c-aba6-7aaafd461a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
