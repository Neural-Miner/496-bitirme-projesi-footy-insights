{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f62bae-5172-4647-b791-13e94cc01086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-411-gf4d8a84c Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: 2\n",
      "✅ Detected Jersey Number: KN\n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n",
      "✅ Detected Jersey Number: \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "# Yolov5 klasörünü ekle\n",
    "sys.path.insert(0, './yolov5')\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.plots import save_one_box\n",
    "\n",
    "# OCR modelleri yükle\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Model yükle (YOLOv5s)\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "device = select_device('')\n",
    "model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "\n",
    "stride, names = model.stride, model.names\n",
    "imgsz = (640, 640)\n",
    "\n",
    "# Test görüntüyü yükle\n",
    "img0 = cv2.imread('Ekran görüntüsü 2025-03-31 152531.png')\n",
    "imgsz = (640, 640)  # veya (512, 512), (416, 416), (320, 320) gibi\n",
    "img = cv2.resize(img0.copy(), imgsz, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "img_tensor = torch.from_numpy(img).to(device).permute(2, 0, 1).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "# Tahmin yap\n",
    "pred = model(img_tensor, augment=False, visualize=False)\n",
    "pred = non_max_suppression(pred, conf_thres=0.4, iou_thres=0.5)[0]\n",
    "\n",
    "# Sonuçları işle\n",
    "if pred is not None and len(pred):\n",
    "    pred[:, :4] = scale_boxes(img_tensor.shape[2:], pred[:, :4], img0.shape).round()\n",
    "\n",
    "    for det in pred:\n",
    "        x1, y1, x2, y2, conf, cls = map(int, det)\n",
    "        torso_crop = save_one_box(det[:4], img0, save=False)\n",
    "\n",
    "        # Opsiyonel: Görüntü iyileştirme (basit sharpening)\n",
    "        torso_crop = cv2.detailEnhance(torso_crop, sigma_s=10, sigma_r=0.15)\n",
    "\n",
    "        # OCR Aşamaları\n",
    "        easy_result = reader.readtext(torso_crop)\n",
    "        easy_text = easy_result[0][1] if easy_result else \"\"\n",
    "\n",
    "        tesseract_text = pytesseract.image_to_string(torso_crop, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "        tesseract_text = tesseract_text.strip()\n",
    "\n",
    "        # (Opsiyonel) parseq_text = call_parseq_model(torso_crop)  # Model kuruluysa\n",
    "\n",
    "        results = [easy_text, tesseract_text]\n",
    "        most_common = Counter(results).most_common(1)[0][0]\n",
    "\n",
    "        print(f\"✅ Detected Jersey Number: {most_common}\")\n",
    "else:\n",
    "    print(\"No players detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d28e62b-62e2-465a-b7be-5546f4366b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-411-gf4d8a84c Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: BENV 66\n",
      "✅ Tespit: 2\n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n",
      "✅ Tespit: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import sys\n",
    "from utils.torch_utils import select_device\n",
    "from utils.plots import save_one_box\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from models.common import DetectMultiBackend\n",
    "\n",
    "# OCR başlat\n",
    "reader = easyocr.Reader(['en'])\n",
    "pytesseract.pytesseract.tesseract_cmd = 'tesseract'\n",
    "\n",
    "# Cihaz seç\n",
    "device = select_device('')\n",
    "model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "model.eval()\n",
    "imgsz = (640, 640)\n",
    "\n",
    "# Görüntü oku ve resize et\n",
    "img0 = cv2.imread('Ekran görüntüsü 2025-03-31 152531.png')\n",
    "img = cv2.resize(img0.copy(), imgsz)\n",
    "img_resized = img[:, :, ::-1].transpose(2, 0, 1)  # BGR→RGB, HWC→CHW\n",
    "img_tensor = torch.from_numpy(np.ascontiguousarray(img_resized)).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "# YOLOv5 ile tahmin\n",
    "with torch.no_grad():\n",
    "    pred = model(img_tensor)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.4, iou_thres=0.5)[0]\n",
    "\n",
    "# Tahmin varsa işleyelim\n",
    "if pred is not None and len(pred):\n",
    "    pred[:, :4] = scale_boxes(img_tensor.shape[2:], pred[:, :4], img0.shape).round()\n",
    "\n",
    "    for *xyxy, conf, cls in pred:\n",
    "        # Oyuncu kutusunu çiz\n",
    "        xyxy = torch.tensor(xyxy).view(1, 4)\n",
    "        crop = save_one_box(xyxy, img0, save=False)\n",
    "\n",
    "        # Opsiyonel iyileştirme\n",
    "        crop = cv2.detailEnhance(crop, sigma_s=10, sigma_r=0.15)\n",
    "\n",
    "        # OCR (ensemble)\n",
    "        easy_result = reader.readtext(crop)\n",
    "        easy_text = easy_result[0][1] if easy_result else \"\"\n",
    "\n",
    "        tess_text = pytesseract.image_to_string(crop, config='--psm 7 -c tessedit_char_whitelist=0123456789').strip()\n",
    "\n",
    "        # Sonuçları birleştir\n",
    "        results = [easy_text, tess_text]\n",
    "        jersey_number = Counter(results).most_common(1)[0][0]\n",
    "\n",
    "        # Görsel üzerine çizim yap\n",
    "        x1, y1, x2, y2 = map(int, xyxy.squeeze())\n",
    "        cv2.rectangle(img0, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img0, f'#{jersey_number}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        print(f\"✅ Tespit: {jersey_number}\")\n",
    "\n",
    "# Sonuç göster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BGR → RGB\n",
    "img_rgb = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Detected Players and Jersey Numbers\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# İsteğe bağlı kaydet\n",
    "cv2.imwrite(\"output_detected.jpg\", img0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5cc3947-8c7b-43ae-8d9a-2b566513aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-411-gf4d8a84c Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gelişmiş Forma Numarası Tespiti Pipeline v2\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# YOLOv5 klasörünü ekle\n",
    "sys.path.insert(0, './yolov5')\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.torch_utils import select_device\n",
    "from utils.plots import save_one_box\n",
    "\n",
    "# OCR modelleri\n",
    "reader = easyocr.Reader(['en'])\n",
    "pytesseract.pytesseract.tesseract_cmd = 'tesseract'\n",
    "\n",
    "# Cihaz seçimi ve model yükleme\n",
    "device = select_device('')\n",
    "model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "model.eval()\n",
    "imgsz = (640, 640)\n",
    "\n",
    "# Yardımcı fonksiyonlar\n",
    "def clean_ocr_result(text):\n",
    "    num = re.sub(r\"[^0-9]\", \"\", text)\n",
    "    if 1 <= len(num) <= 2:\n",
    "        return num\n",
    "    return \"\"\n",
    "\n",
    "def is_valid_box(x1, y1, x2, y2, img_height):\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    if h < 40 or w < 20 or h/w > 6:\n",
    "        return False\n",
    "    if y2 < img_height * 0.3:\n",
    "        return False  # Üst kısımlar genellikle yazı olur\n",
    "    return True\n",
    "\n",
    "def crop_lower_half(box):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    h = y2 - y1\n",
    "    return [x1, y1 + int(h * 0.5), x2, y2]\n",
    "\n",
    "# Görüntü yükle ve resize et\n",
    "img0 = cv2.imread('Ekran görüntüsü 2025-03-31 152531.png')\n",
    "img = cv2.resize(img0.copy(), imgsz)\n",
    "img_resized = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "img_tensor = torch.from_numpy(np.ascontiguousarray(img_resized)).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "# Tahmin\n",
    "with torch.no_grad():\n",
    "    pred = model(img_tensor)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.5)[0]\n",
    "\n",
    "# Tahmin varsa işle\n",
    "if pred is not None and len(pred):\n",
    "    pred[:, :4] = scale_boxes(img_tensor.shape[2:], pred[:, :4], img0.shape).round()\n",
    "\n",
    "    for *xyxy, conf, cls in pred:\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        if not is_valid_box(x1, y1, x2, y2, img0.shape[0]):\n",
    "            continue\n",
    "\n",
    "        # Alt yarıyı crop et\n",
    "        crop_box = crop_lower_half([x1, y1, x2, y2])\n",
    "        torso_crop = img0[crop_box[1]:crop_box[3], crop_box[0]:crop_box[2]]\n",
    "\n",
    "        # OCR\n",
    "        easy_result = reader.readtext(torso_crop)\n",
    "        easy_text = easy_result[0][1] if easy_result else \"\"\n",
    "\n",
    "        tess_text = pytesseract.image_to_string(\n",
    "            torso_crop, config='--psm 7 -c tessedit_char_whitelist=0123456789')\n",
    "\n",
    "        # Ensemble ve temizleme\n",
    "        results = [easy_text, tess_text.strip()]\n",
    "        jersey_number = Counter(map(clean_ocr_result, results)).most_common(1)[0][0]\n",
    "\n",
    "        # Çizim\n",
    "        cv2.rectangle(img0, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        if jersey_number:\n",
    "            cv2.putText(img0, f'#{jersey_number}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            print(f\"✅ Tespit: {jersey_number}\")\n",
    "\n",
    "# Görseli göster (Matplotlib)\n",
    "img_rgb = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Detected Players and Jersey Numbers\")\n",
    "plt.show()\n",
    "\n",
    "# Sonuçu kaydet\n",
    "cv2.imwrite(\"output_detected1.jpg\", img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb81f6-3931-4441-b52f-371ed510427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelişmiş Forma Numarası Tespiti Pipeline v2 (PARSeq destekli)\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# YOLOv5 klasörü\n",
    "sys.path.insert(0, './yolov5')\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.torch_utils import select_device\n",
    "from utils.plots import save_one_box\n",
    "\n",
    "# OCR modelleri\n",
    "reader = easyocr.Reader(['en'])\n",
    "pytesseract.pytesseract.tesseract_cmd = 'tesseract'\n",
    "\n",
    "# PARSeq modeli\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "parseq_model = VisionEncoderDecoderModel.from_pretrained(\"facebook/parseq\")\n",
    "parseq_processor = TrOCRProcessor.from_pretrained(\"facebook/parseq\")\n",
    "parseq_model.eval()\n",
    "\n",
    "# Cihaz seçimi ve model yükleme\n",
    "device = select_device('')\n",
    "model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "model.eval()\n",
    "imgsz = (640, 640)\n",
    "\n",
    "# Yardımcı fonksiyonlar\n",
    "def clean_ocr_result(text):\n",
    "    num = re.sub(r\"[^0-9]\", \"\", text)\n",
    "    if 1 <= len(num) <= 2:\n",
    "        return num\n",
    "    return \"\"\n",
    "\n",
    "def is_valid_box(x1, y1, x2, y2, img_height):\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    if h < 40 or w < 20 or h/w > 6:\n",
    "        return False\n",
    "    if y2 < img_height * 0.3:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def crop_lower_half(box):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    h = y2 - y1\n",
    "    return [x1, y1 + int(h * 0.35), x2, y2]  # alt %65'i al\n",
    "\n",
    "def run_parseq(img_crop):\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB))\n",
    "    inputs = parseq_processor(images=pil_img, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        generated_ids = parseq_model.generate(**inputs)\n",
    "    text = parseq_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return text.strip()\n",
    "\n",
    "# Görüntü yükle\n",
    "img0 = cv2.imread('Ekran görüntüsü 2025-03-31 152531.png')\n",
    "img = cv2.resize(img0.copy(), imgsz)\n",
    "img_resized = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "img_tensor = torch.from_numpy(np.ascontiguousarray(img_resized)).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "# Tahmin\n",
    "with torch.no_grad():\n",
    "    pred = model(img_tensor)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.5)[0]\n",
    "\n",
    "if pred is not None and len(pred):\n",
    "    pred[:, :4] = scale_boxes(img_tensor.shape[2:], pred[:, :4], img0.shape).round()\n",
    "\n",
    "    for *xyxy, conf, cls in pred:\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        if not is_valid_box(x1, y1, x2, y2, img0.shape[0]):\n",
    "            continue\n",
    "\n",
    "        crop_box = crop_lower_half([x1, y1, x2, y2])\n",
    "        torso_crop = img0[crop_box[1]:crop_box[3], crop_box[0]:crop_box[2]]\n",
    "\n",
    "        easy_result = reader.readtext(torso_crop)\n",
    "        easy_text = easy_result[0][1] if easy_result else \"\"\n",
    "\n",
    "        tess_text = pytesseract.image_to_string(\n",
    "            torso_crop, config='--psm 7 -c tessedit_char_whitelist=0123456789').strip()\n",
    "\n",
    "        parseq_text = run_parseq(torso_crop)\n",
    "\n",
    "        results = [easy_text, tess_text, parseq_text]\n",
    "        jersey_number = Counter(map(clean_ocr_result, results)).most_common(1)[0][0]\n",
    "\n",
    "        cv2.rectangle(img0, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        if jersey_number:\n",
    "            cv2.putText(img0, f'#{jersey_number}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            print(f\"✅ Tespit: {jersey_number}\")\n",
    "\n",
    "# Görseli göster\n",
    "img_rgb = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Detected Players and Jersey Numbers\")\n",
    "plt.show()\n",
    "\n",
    "# Kaydet\n",
    "cv2.imwrite(\"output_detected2.jpg\", img0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
