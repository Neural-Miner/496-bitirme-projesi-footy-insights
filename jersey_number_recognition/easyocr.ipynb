{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b815b395-119d-4ca6-b244-c1f468e14f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-25 Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "\n",
    "# YOLOv5 ile oyuncu deteksiyonu\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "def detect_players(image):\n",
    "    results = model(image)\n",
    "    players = []\n",
    "    for *box, conf, cls in results.xyxy[0]:\n",
    "        if int(cls) == 0:  # 'person' class\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            torso = image[y1:y1 + (y2 - y1)//2, x1:x2]  # sadece gövde\n",
    "            players.append(torso)\n",
    "    return players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e86713a-dbb4-41d9-8257-151ccf51ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ea05203-e529-4d9c-9be9-d1ae2008e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_image(img):\n",
    "    # Basit sharpen + resize + denoise\n",
    "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "    sharp = cv2.filter2D(img, -1, kernel)\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(sharp, None, 10, 10, 7, 21)\n",
    "    return denoised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7166936b-cb8c-45ab-bd95-30b3e584f076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"fatal: destination path 'parseq' already exists and is not an empty directory.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!git clone https://github.com/baudm/parseq.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e65c30d-16d0-46d4-b69c-1a6c2d38b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./parseq')  # parseq klasörün bulunduğu yer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60f78141-e395-4746-a473-32afb4f47952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.git-blame-ignore-revs',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " 'bench.py',\n",
       " 'configs',\n",
       " 'Datasets.md',\n",
       " 'demo_images',\n",
       " 'hubconf.py',\n",
       " 'LICENSE',\n",
       " 'Makefile',\n",
       " 'NOTICE',\n",
       " 'pyproject.toml',\n",
       " 'read.py',\n",
       " 'README.md',\n",
       " 'requirements',\n",
       " 'strhub',\n",
       " 'test.py',\n",
       " 'tools',\n",
       " 'train.py',\n",
       " 'tune.py']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('./parseq')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ec331a-750e-4910-8677-3feec5f7e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/abhishek4273/parseq.git parseq_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e3712d3-5d13-4408-95a9-79f361e55ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\timm\\models\\helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from strhub.models.utils import load_from_checkpoint\n",
    "from collections import Counter\n",
    "\n",
    "# OCR okuyucuları başlat\n",
    "easy_reader = easyocr.Reader(['en'])\n",
    "\n",
    "# PARSeq yükleniyor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "parseq = load_from_checkpoint('pretrained=parseq').eval().to(device)\n",
    "\n",
    "# Görüntüyü PARSeq için hazırla\n",
    "def prepare_image(img):\n",
    "    if isinstance(img, str):  # path verilmişse\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "    elif isinstance(img, Image.Image):  # PIL image ise OK\n",
    "        img = img.convert(\"RGB\")\n",
    "    else:\n",
    "        raise ValueError(\"Girdi PIL Image ya da dosya yolu olmalı.\")\n",
    "    transform = transforms.ToTensor()\n",
    "    return transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "# Jersey number okuma fonksiyonu\n",
    "def read_jersey_number(img):\n",
    "    results = []\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_result = easy_reader.readtext(img)\n",
    "    if easy_result:\n",
    "        results.append(easy_result[0][1])\n",
    "\n",
    "    # Tesseract\n",
    "    tess_result = pytesseract.image_to_string(img, config='--psm 6 digits')\n",
    "    if tess_result.strip():\n",
    "        results.append(tess_result.strip())\n",
    "\n",
    "    # PARSeq\n",
    "    try:\n",
    "        tensor_img = prepare_image(img)\n",
    "        with torch.no_grad():\n",
    "            logits = parseq(tensor_img)\n",
    "            pred = logits.argmax(-1)\n",
    "            text = parseq.tokenizer.decode(pred)[0]\n",
    "            if text:\n",
    "                results.append(text)\n",
    "    except Exception as e:\n",
    "        print(\"PARSeq hatası:\", e)\n",
    "\n",
    "    # Majority vote\n",
    "    return Counter(results).most_common(1)[0][0] if results else \"?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b18ae30f-1eeb-4eb9-93ac-26cef02e9d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==1.9.5\n",
      "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (1.26.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (2.6.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (6.0.2)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (2024.6.1)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.5)\n",
      "  Using cached torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from pytorch-lightning==1.9.5) (4.12.2)\n",
      "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning==1.9.5)\n",
      "  Using cached lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached aiohttp-3.11.14-cp39-cp39-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning==1.9.5) (75.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->pytorch-lightning==1.9.5) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning==1.9.5) (0.4.6)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached multidict-6.2.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Downloading propcache-0.3.1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5)\n",
      "  Using cached yarl-1.18.3-cp39-cp39-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.5) (2.1.5)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (3.10)\n",
      "Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "Using cached lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
      "Using cached torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
      "Using cached aiohttp-3.11.14-cp39-cp39-win_amd64.whl (443 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.2.0-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Downloading propcache-0.3.1-cp39-cp39-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.18.3-cp39-cp39-win_amd64.whl (90 kB)\n",
      "Installing collected packages: propcache, multidict, lightning-utilities, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 lightning-utilities-0.14.2 multidict-6.2.0 propcache-0.3.1 pytorch-lightning-1.9.5 torchmetrics-1.7.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning==1.9.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8354aa03-883b-4572-aa1a-f1cdf1784f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.8 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f70336a-6b0a-47c4-b53e-c01cb6177682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Using cached timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from timm) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from timm) (0.21.0+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from timm) (6.0.2)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-0.30.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torchvision->timm) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from torchvision->timm) (11.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uysal\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Using cached timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "Downloading huggingface_hub-0.30.0-py3-none-any.whl (481 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.30.0 safetensors-0.5.3 timm-1.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b335c698-3358-4729-ad22-eb03eb1e1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uysal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n",
      "PARSeq hatası: Girdi PIL Image ya da dosya yolu olmalı.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_path = r\"C:\\Users\\uysal\\OneDrive\\Resimler\\Ekran Görüntüleri\\Ekran görüntüsü 2025-03-31 152531.png\"\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "players = detect_players(img_rgb)\n",
    "\n",
    "for i, torso in enumerate(players):\n",
    "    enhanced = enhance_image(torso)\n",
    "    number = read_jersey_number(enhanced)\n",
    "    \n",
    "    plt.imshow(enhanced)\n",
    "    plt.title(f'Player {i+1} - Jersey #: {number}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b46510-077d-4901-8ff6-dce12fa926c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3886fea-47f2-44fb-b8c7-4b8b9db6f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_reader = easyocr.Reader(['en'])  # dil modeli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f76370a-6d0c-47d5-9cd3-267b41526b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def parseq_predict(image_path):\n",
    "    command = f\"python parseq/test.py --checkpoint parseq/pretrained/parseq.pt --img {image_path} --topk 1\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    for line in result.stdout.splitlines():\n",
    "        if \"Prediction:\" in line:\n",
    "            return line.split(\"Prediction:\")[1].strip()\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3cb20b5-e3bc-4a78-9c8b-7918fcaa6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jersey_number(img, img_path_for_parseq):\n",
    "    results = []\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_result = easy_reader.readtext(img)\n",
    "    if easy_result:\n",
    "        results.append(easy_result[0][1])\n",
    "\n",
    "    # Tesseract\n",
    "    tess_result = pytesseract.image_to_string(img, config='--psm 6 digits')\n",
    "    if tess_result.strip():\n",
    "        results.append(tess_result.strip())\n",
    "\n",
    "    # PARSeq\n",
    "    parseq_result = parseq_predict(img_path_for_parseq)\n",
    "    if parseq_result:\n",
    "        results.append(parseq_result)\n",
    "\n",
    "    return Counter(results).most_common(1)[0][0] if results else \"?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f873e455-556e-44c2-926d-9bbc5e6d7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    enhanced = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    return enhanced\n",
    "\n",
    "def detect_players(img_rgb):\n",
    "    # Yerine gerçek YOLO entegre edilecek\n",
    "    h, w, _ = img_rgb.shape\n",
    "    # Şimdilik rastgele crop örneği verelim (dummy bboxlar)\n",
    "    crops = [img_rgb[50:150, 100:200], img_rgb[120:220, 250:350]]\n",
    "    return crops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "047db858-57f4-4369-b684-7e4ea10e5ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_player_0.png saved: True\n",
      "temp_player_1.png saved: True\n"
     ]
    }
   ],
   "source": [
    "image_path = \"Ekran görüntüsü 2025-03-31 152531.png\"  # test görselin yolu\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "players = detect_players(img_rgb)\n",
    "\n",
    "for i, torso in enumerate(players):\n",
    "    enhanced = enhance_image(torso)\n",
    "    \n",
    "    # PARSeq için görseli kaydet\n",
    "    temp_path = f\"temp_player_{i}.png\"\n",
    "    cv2.imwrite(temp_path, enhanced)\n",
    "    success = cv2.imwrite(temp_path, enhanced)\n",
    "    print(f\"{temp_path} saved:\", success)\n",
    "\n",
    "    number = read_jersey_number(enhanced, temp_path)\n",
    "\n",
    "    plt.imshow(enhanced, cmap='gray')\n",
    "    plt.title(f\"Player {i+1} - Jersey #: {number}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    os.remove(temp_path)  # temp dosyayı sil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dec8972a-ae4a-4318-a874-4c3be65730fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp_player_1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_player_1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# veya elindeki başka bir görselin yolu\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Görseli yükle\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# BGR'den RGB'ye çevir (OpenCV BGR formatındadır)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp_player_1.png'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Görselin yolu\n",
    "image_path = \"temp_player_1.png\"  # veya elindeki başka bir görselin yolu\n",
    "\n",
    "# Görseli yükle\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# BGR'den RGB'ye çevir (OpenCV BGR formatındadır)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Notebook'ta göster\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Görsel Önizleme\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5b6d74b-bb2f-43d4-a840-8af4415f562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PARSeq yolunu ekle\n",
    "import sys\n",
    "sys.path.append('./parseq')\n",
    "\n",
    "from strhub.models.utils import load_from_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274083a-edab-4629-876b-3ff1045f992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "parseq_model = load_from_checkpoint('pretrained=parseq').eval().to(device)\n",
    "\n",
    "# PARSeq için transform\n",
    "parseq_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "361bab1e-c3b4-4319-bc3b-b8966b2a644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_reader = easyocr.Reader(['en'])\n",
    "\n",
    "def read_jersey_number(img_bgr, save_path):\n",
    "    results = []\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_result = easy_reader.readtext(img_bgr)\n",
    "    if easy_result:\n",
    "        results.append(easy_result[0][1])\n",
    "\n",
    "    # Tesseract\n",
    "    tess_result = pytesseract.image_to_string(img_bgr, config='--psm 6 digits')\n",
    "    if tess_result.strip():\n",
    "        results.append(tess_result.strip())\n",
    "\n",
    "    # PARSeq\n",
    "    img_pil = Image.open(save_path).convert('RGB')\n",
    "    img_tensor = parseq_transform(img_pil).unsqueeze(0).to(device)\n",
    "    parseq_result = parseq_model(img_tensor)[0]\n",
    "    if parseq_result:\n",
    "        results.append(parseq_result)\n",
    "\n",
    "    return Counter(results).most_common(1)[0][0] if results else \"?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a808d893-3f7a-44a9-be9c-cdcbe9e20e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_players(img_rgb):\n",
    "    h, w, _ = img_rgb.shape\n",
    "    torso1 = img_rgb[h//4:h//2, w//4:w//2]\n",
    "    torso2 = img_rgb[h//4:h//2, w//2:w*3//4]\n",
    "    return [torso1, torso2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe572be9-1ef6-4218-b8a7-b022b5dcc9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.equalizeHist(gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba363809-63ed-4df6-bdbe-856bbf8c4d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m temp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_player_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(temp_path, enhanced)\n\u001b[1;32m---> 14\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[43mread_jersey_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Görseli göster\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(enhanced, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 20\u001b[0m, in \u001b[0;36mread_jersey_number\u001b[1;34m(img_bgr, save_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m parseq_transform(img_pil)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m parseq_result \u001b[38;5;241m=\u001b[39m parseq_model(img_tensor)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parseq_result:\n\u001b[0;32m     21\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(parseq_result)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Counter(results)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "image_path = \"Ekran görüntüsü 2025-03-31 152531.png\"\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "players = detect_players(img_rgb)\n",
    "\n",
    "for i, torso in enumerate(players):\n",
    "    enhanced = enhance_image(torso)\n",
    "\n",
    "    # Geçici olarak kaydet (PARSeq için)\n",
    "    temp_path = f\"temp_player_{i}.png\"\n",
    "    cv2.imwrite(temp_path, enhanced)\n",
    "\n",
    "    number = read_jersey_number(enhanced, temp_path)\n",
    "\n",
    "    # Görseli göster\n",
    "    plt.imshow(enhanced, cmap='gray')\n",
    "    plt.title(f\"Player {i+1} - Jersey #: {number}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    os.remove(temp_path)\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "players = detect_players(img_rgb)\n",
    "\n",
    "for i, torso in enumerate(players):\n",
    "    enhanced = enhance_image(torso)\n",
    "\n",
    "    # Geçici olarak kaydet (PARSeq için)\n",
    "    temp_path = f\"temp_player_{i}.png\"\n",
    "    cv2.imwrite(temp_path, enhanced)\n",
    "\n",
    "    number = read_jersey_number(enhanced, temp_path)\n",
    "\n",
    "    # Görseli göster\n",
    "    plt.imshow(enhanced, cmap='gray')\n",
    "    plt.title(f\"Player {i+1} - Jersey #: {number}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    os.remove(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfc149eb-2798-4dcd-ab54-f853ec0250e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PARSeq' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m temp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_player_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(temp_path, enhanced)\n\u001b[1;32m---> 70\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[43mread_jersey_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Görseli göster\u001b[39;00m\n\u001b[0;32m     73\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(enhanced, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[54], line 48\u001b[0m, in \u001b[0;36mread_jersey_number\u001b[1;34m(img_bgr, save_path)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# PARSeq\u001b[39;00m\n\u001b[0;32m     47\u001b[0m img_pil \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(save_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mparseq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m(img_pil)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     49\u001b[0m parseq_result \u001b[38;5;241m=\u001b[39m parseq_model(img_tensor)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parseq_result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jerseyocr2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1930\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PARSeq' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "# --- Gerekli kütüphaneler ---\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from parseq.strhub.models.utils import load_from_checkpoint\n",
    "\n",
    "# --- PARSeq modeli yükleniyor ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "parseq_model = load_from_checkpoint('pretrained=parseq').eval().to(device)\n",
    "\n",
    "# --- EasyOCR hazırla ---\n",
    "easy_reader = easyocr.Reader(['en'])\n",
    "\n",
    "# --- Oyuncu tespiti (placeholder) ---\n",
    "def detect_players(image):\n",
    "    # Bu, oyuncuları bulmak için YOLO gibi bir model kullanmalı\n",
    "    # şu anda dummy olarak sadece tüm resmi döndürüyoruz\n",
    "    return [image]\n",
    "\n",
    "# --- Görsel iyileştirme ---\n",
    "def enhance_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(gray, (128, 32))  # PARSeq için uygun boyut\n",
    "    return resized\n",
    "\n",
    "# --- Forma numarasını okuma ---\n",
    "def read_jersey_number(img_bgr, save_path):\n",
    "    results = []\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_result = easy_reader.readtext(save_path)\n",
    "    if len(easy_result) > 0:\n",
    "        results.append(easy_result[0][1])\n",
    "\n",
    "    # Tesseract\n",
    "    tess_result = pytesseract.image_to_string(save_path, config='--psm 6 digits')\n",
    "    if tess_result.strip():\n",
    "        results.append(tess_result.strip())\n",
    "\n",
    "    # PARSeq\n",
    "    img_pil = Image.open(save_path).convert('RGB')\n",
    "    img_tensor = parseq_model.transform(img_pil).unsqueeze(0).to(device)\n",
    "    parseq_result = parseq_model(img_tensor)[0]\n",
    "    if len(parseq_result) > 0:\n",
    "        results.append(parseq_result)\n",
    "\n",
    "    # Majority vote\n",
    "    return Counter(results).most_common(1)[0][0] if results else \"?\"\n",
    "\n",
    "# --- Test ---\n",
    "image_path = \"Ekran görüntüsü 2025-03-31 152531.png\"  # Buraya test görselinin yolunu ver\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "players = detect_players(img_rgb)\n",
    "\n",
    "for i, torso in enumerate(players):\n",
    "    enhanced = enhance_image(torso)\n",
    "\n",
    "    # Geçici olarak kaydet (PARSeq için)\n",
    "    temp_path = f\"temp_player_{i}.png\"\n",
    "    cv2.imwrite(temp_path, enhanced)\n",
    "\n",
    "    number = read_jersey_number(enhanced, temp_path)\n",
    "\n",
    "    # Görseli göster\n",
    "    plt.imshow(enhanced, cmap='gray')\n",
    "    plt.title(f\"Player {i+1} - Jersey #: {number}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    os.remove(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0464044-4783-484d-a7ca-6dbac39d7143",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parseq.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# PARSeq modeli ve transform\u001b[39;00m\n\u001b[0;32m     21\u001b[0m parseq_model \u001b[38;5;241m=\u001b[39m load_from_checkpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained=parseq\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mparseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_transform\n\u001b[0;32m     24\u001b[0m transform \u001b[38;5;241m=\u001b[39m get_transform(img_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m128\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Jersey numarası okuma fonksiyonu\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'parseq.utils'"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneler\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from parseq.strhub.models.utils import load_from_checkpoint\n",
    "from parseq.strhub.data.module import SceneTextDataModule\n",
    "\n",
    "# EasyOCR\n",
    "easy_reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Cihaz\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# PARSeq modeli ve transform\n",
    "parseq_model = load_from_checkpoint('pretrained=parseq').eval().to(device)\n",
    "from parseq.utils import get_transform\n",
    "\n",
    "transform = get_transform(img_size=(32, 128))\n",
    "\n",
    "\n",
    "# Jersey numarası okuma fonksiyonu\n",
    "def read_jersey_number(img_bgr, save_path):\n",
    "    results = []\n",
    "\n",
    "    # EasyOCR\n",
    "    easy_result = easy_reader.readtext(img_bgr)\n",
    "    if easy_result:\n",
    "        results.append(easy_result[0][1])\n",
    "\n",
    "    # Tesseract\n",
    "    tess_result = pytesseract.image_to_string(img_bgr, config='--psm 6 digits')\n",
    "    if tess_result.strip():\n",
    "        results.append(tess_result.strip())\n",
    "\n",
    "    # PARSeq\n",
    "    img_pil = Image.open(save_path).convert('RGB')\n",
    "    img_tensor = transform(image=img_pil)[\"image\"].unsqueeze(0).to(device)\n",
    "    parseq_result = parseq_model(img_tensor)[0]\n",
    "    if len(parseq_result) > 0:\n",
    "        results.append(parseq_result)\n",
    "\n",
    "    return Counter(results).most_common(1)[0][0] if results else \"?\"\n",
    "\n",
    "# Dummy torso tespit fonksiyonu (test için rastgele bölge seçer)\n",
    "def detect_players(image_rgb):\n",
    "    h, w, _ = image_rgb.shape\n",
    "    players = []\n",
    "    for i in range(3):  # Örnek olarak 3 oyuncu crop'luyoruz\n",
    "        y1 = int(h * (0.2 + 0.2 * i))\n",
    "        y2 = y1 + int(h * 0.15)\n",
    "        x1 = int(w * 0.4)\n",
    "        x2 = x1 + int(w * 0.2)\n",
    "        torso = image_rgb[y1:y2, x1:x2]\n",
    "        players.append(torso)\n",
    "    return players\n",
    "\n",
    "# Görüntü iyileştirme (isteğe bağlı basit enhance)\n",
    "def enhance_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    enhanced = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    return enhanced\n",
    "\n",
    "# Test başlat\n",
    "def test_pipeline(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    players = detect_players(img_rgb)\n",
    "\n",
    "    for i, torso in enumerate(players):\n",
    "        enhanced = enhance_image(torso)\n",
    "\n",
    "        temp_path = f\"temp_player_{i}.png\"\n",
    "        cv2.imwrite(temp_path, enhanced)\n",
    "\n",
    "        number = read_jersey_number(enhanced, temp_path)\n",
    "\n",
    "        plt.imshow(enhanced, cmap='gray')\n",
    "        plt.title(f\"Player {i+1} - Jersey #: {number}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        os.remove(temp_path)\n",
    "\n",
    "# Örnek test\n",
    "test_pipeline(\"Ekran görüntüsü 2025-03-31 152531.png\")  # Buraya test görselinin yolunu yaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8830584c-8e68-4fd0-b46f-b2baeda93f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb\n",
      "  Using cached lmdb-1.6.2-cp39-cp39-win_amd64.whl.metadata (1.2 kB)\n",
      "Using cached lmdb-1.6.2-cp39-cp39-win_amd64.whl (106 kB)\n",
      "Installing collected packages: lmdb\n",
      "Successfully installed lmdb-1.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeea07-9279-4610-b546-8f77d291b441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
