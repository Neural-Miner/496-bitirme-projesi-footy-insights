{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYj0ycKJD5Hg",
        "outputId": "c4b7e536-54aa-47bc-e47f-342a9237049c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU kontrolü\n",
        "!nvidia-smi\n",
        "\n",
        "# Çalışma dizinini sıfırlama\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9i4_2iyZwbS",
        "outputId": "9ca8e164-93ab-403a-a9e9-3414212262d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.cluster import DBSCAN\n",
        "import torch\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Gerekli kütüphanelerin kurulumu\n",
        "!pip install -q ultralytics\n",
        "!pip install -q pytesseract\n",
        "!apt-get install tesseract-ocr -y\n",
        "!pip install -q scenedetect[opencv]\n",
        "!pip install -q supervision\n",
        "\n",
        "# Scene Detection için gerekli kütüphaneleri içe aktar\n",
        "from scenedetect import VideoManager\n",
        "from scenedetect import SceneManager\n",
        "from scenedetect.detectors import ContentDetector\n",
        "\n",
        "# Tesseract OCR'ı yapılandır\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# YOLO modellerini yükle\n",
        "person_model = YOLO('yolov8x.pt')  # Kişi tespiti için daha büyük model\n",
        "ocr_model = YOLO('yolov8n.pt')     # Forma numarası için hafif model\n",
        "\n",
        "def download_models():\n",
        "    \"\"\"Gerekli modelleri indir\"\"\"\n",
        "    print(\"YOLO modellerini indirme...\")\n",
        "    # Modeller zaten import edildiğinde yüklenir\n",
        "\n",
        "def detect_scenes(video_path, threshold=30.0):\n",
        "    \"\"\"\n",
        "    Videodaki sahne değişimlerini tespit eder\n",
        "    Args:\n",
        "        video_path: Video dosyasının yolu\n",
        "        threshold: Sahne değişimi için eşik değeri\n",
        "    Returns:\n",
        "        scenes: Sahne başlangıç ve bitiş frame numaralarının listesi\n",
        "    \"\"\"\n",
        "    print(\"Sahneleri tespit etme...\")\n",
        "\n",
        "    # VideoManager ve SceneManager oluştur\n",
        "    video_manager = VideoManager([video_path])\n",
        "    scene_manager = SceneManager()\n",
        "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
        "\n",
        "    # Video işleme başla\n",
        "    video_manager.start()\n",
        "    scene_manager.detect_scenes(frame_source=video_manager)\n",
        "\n",
        "    # Sahneleri al\n",
        "    scene_list = scene_manager.get_scene_list()\n",
        "\n",
        "    # Frame numaralarına dönüştür\n",
        "    scenes = []\n",
        "    for scene in scene_list:\n",
        "        scenes.append((scene[0].frame_num, scene[1].frame_num))\n",
        "\n",
        "    print(f\"Toplam {len(scenes)} sahne tespit edildi.\")\n",
        "    return scenes\n",
        "\n",
        "def detect_and_track_players(video_path, scene, scene_id):\n",
        "    \"\"\"\n",
        "    Sahnedeki oyuncuları tespit eder ve takip eder\n",
        "    Args:\n",
        "        video_path: Video dosyasının yolu\n",
        "        scene: (başlangıç_frame, bitiş_frame) şeklinde sahne bilgisi\n",
        "        scene_id: Sahne ID'si\n",
        "    Returns:\n",
        "        players: Her oyuncu için track ID ve frame'lerini içeren sözlük\n",
        "    \"\"\"\n",
        "    print(f\"Sahne {scene_id} için oyuncuları tespit etme ve takip etme...\")\n",
        "\n",
        "    # Video dosyasını aç\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Sahnenin başlangıç frame'ine git\n",
        "    start_frame, end_frame = scene\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "    # Oyuncular için sözlük\n",
        "    players = {}\n",
        "    next_id = 1  # Her sahne için ID'leri sıfırla\n",
        "\n",
        "    # Oyuncu izleme için önceki tespit sonuçlarını sakla\n",
        "    prev_boxes = []\n",
        "    prev_ids = []\n",
        "\n",
        "    frame_idx = start_frame\n",
        "\n",
        "    # Sahne boyunca frame'leri işle\n",
        "    while frame_idx < end_frame:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Kişileri tespit et\n",
        "        results = person_model(frame, classes=0)  # Sadece kişileri tespit et (class 0)\n",
        "\n",
        "        # Tespit edilen kişilerin bounding box'larını al\n",
        "        current_boxes = []\n",
        "        for box in results[0].boxes.xyxy.cpu().numpy():\n",
        "            current_boxes.append(box)\n",
        "\n",
        "        current_boxes = np.array(current_boxes)\n",
        "\n",
        "        # İlk frame ise, her kişiye yeni bir ID ata\n",
        "        if len(prev_boxes) == 0 and len(current_boxes) > 0:\n",
        "            current_ids = list(range(next_id, next_id + len(current_boxes)))\n",
        "            next_id += len(current_boxes)\n",
        "        # Diğer frame'ler için, IOU tabanlı takip yap\n",
        "        elif len(current_boxes) > 0 and len(prev_boxes) > 0:\n",
        "            current_ids = [-1] * len(current_boxes)\n",
        "\n",
        "            # Her mevcut kutu için en iyi eşleşmeyi bul\n",
        "            for i, current_box in enumerate(current_boxes):\n",
        "                best_iou = 0.3  # IOU eşiği\n",
        "                best_id = -1\n",
        "\n",
        "                for j, prev_box in enumerate(prev_boxes):\n",
        "                    iou = calculate_iou(current_box, prev_box)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_id = prev_ids[j]\n",
        "\n",
        "                if best_id != -1:\n",
        "                    current_ids[i] = best_id\n",
        "                else:\n",
        "                    # Eşleşme bulunamazsa yeni ID ata\n",
        "                    current_ids[i] = next_id\n",
        "                    next_id += 1\n",
        "        else:\n",
        "            current_ids = []\n",
        "\n",
        "        # Tespit edilen oyuncuları kaydet\n",
        "        for i, box in enumerate(current_boxes):\n",
        "            player_id = current_ids[i]\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "            # Yeni bir oyuncu ise, sözlüğe ekle\n",
        "            if player_id not in players:\n",
        "                players[player_id] = []\n",
        "\n",
        "            # Oyuncunun bu frame'deki görüntüsünü kaydet\n",
        "            player_crop = frame[y1:y2, x1:x2]\n",
        "            frame_info = {\n",
        "                'frame_num': frame_idx,\n",
        "                'crop': player_crop,\n",
        "                'box': (x1, y1, x2, y2)\n",
        "            }\n",
        "            players[player_id].append(frame_info)\n",
        "\n",
        "        # Mevcut frame'i bir sonraki işlem için sakla\n",
        "        prev_boxes = current_boxes\n",
        "        prev_ids = current_ids\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Çok az frame'de görünen oyuncuları (muhtemelen yanlış tespitler) filtrele\n",
        "    filtered_players = {k: v for k, v in players.items() if len(v) > 5}\n",
        "\n",
        "    print(f\"Sahne {scene_id} için {len(filtered_players)} oyuncu tespit edildi ve takip edildi.\")\n",
        "    return filtered_players\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    İki bounding box arasındaki IOU (Intersection over Union) değerini hesaplar\n",
        "    \"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    # Kesişim alanını hesapla\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i < x1_i or y2_i < y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "\n",
        "    # Birleşim alanını hesapla\n",
        "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def extract_jersey_region(player_frames):\n",
        "    \"\"\"\n",
        "    Oyuncunun her frame'i için forma bölgesini tespit eder\n",
        "    Args:\n",
        "        player_frames: Oyuncunun frame bilgilerini içeren liste\n",
        "    Returns:\n",
        "        jersey_crops: Forma bölgesi kesitlerini içeren liste\n",
        "    \"\"\"\n",
        "    jersey_crops = []\n",
        "\n",
        "    for frame_info in player_frames:\n",
        "        crop = frame_info['crop']\n",
        "\n",
        "        if crop.size == 0 or crop.shape[0] < 10 or crop.shape[1] < 10:\n",
        "            continue\n",
        "\n",
        "        # Forma bölgesi, genellikle vücudun üst kısmındadır\n",
        "        h, w = crop.shape[:2]\n",
        "\n",
        "        # Üst 1/3 ve orta 1/3 bölgeyi al (forma genellikle burada olur)\n",
        "        jersey_region = crop[int(h*0.15):int(h*0.6), int(w*0.1):int(w*0.9)]\n",
        "\n",
        "        if jersey_region.size == 0 or jersey_region.shape[0] < 10 or jersey_region.shape[1] < 10:\n",
        "            continue\n",
        "\n",
        "        # Görüntü iyileştirme\n",
        "        jersey_region = enhance_image(jersey_region)\n",
        "\n",
        "        jersey_crops.append(jersey_region)\n",
        "\n",
        "    return jersey_crops\n",
        "\n",
        "def enhance_image(image):\n",
        "    \"\"\"\n",
        "    Forma numarasının daha iyi algılanması için görüntüyü iyileştirir\n",
        "    \"\"\"\n",
        "    # Görüntü boyutu çok küçükse yeniden boyutlandır\n",
        "    if image.shape[0] < 60 or image.shape[1] < 60:\n",
        "        scale_factor = max(60 / image.shape[0], 60 / image.shape[1])\n",
        "        new_size = (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor))\n",
        "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Gri tonlamaya dönüştür\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Adaptif eşikleme uygula\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    # Morfolojik işlemlerle gürültüyü azalt\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Kenarları belirginleştir\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "    # Orijinal görüntüyü kontrastını artır\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    enhanced_gray = clahe.apply(gray)\n",
        "\n",
        "    # BGR'a dönüştür\n",
        "    enhanced = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "def recognize_jersey_number(jersey_crops):\n",
        "    \"\"\"\n",
        "    Forma kesitlerinden numara tespiti yapar\n",
        "    Args:\n",
        "        jersey_crops: Forma bölgesi kesitlerinin listesi\n",
        "    Returns:\n",
        "        jersey_number: En çok tespit edilen forma numarası\n",
        "    \"\"\"\n",
        "    if not jersey_crops:\n",
        "        return None\n",
        "\n",
        "    numbers = []\n",
        "\n",
        "    for jersey in jersey_crops:\n",
        "        # Tesseract ile OCR uygula\n",
        "        # Sadece rakamları tespit etmek için konfigürasyon ayarı\n",
        "        text = pytesseract.image_to_string(jersey, config='--psm 6 -c tessedit_char_whitelist=0123456789')\n",
        "\n",
        "        # Bulunan metni temizle ve sayıları çıkar\n",
        "        if text.strip():\n",
        "            try:\n",
        "                # İlk bulunan sayıyı al\n",
        "                for char in text:\n",
        "                    if char.isdigit():\n",
        "                        numbers.append(int(char))\n",
        "                        break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # En sık tespit edilen numarayı bul (majority voting)\n",
        "    if numbers:\n",
        "        counter = Counter(numbers)\n",
        "        most_common = counter.most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "    return None\n",
        "\n",
        "def process_video(video_path, output_dir='output'):\n",
        "    \"\"\"\n",
        "    Videoyu tam olarak işleyen ana fonksiyon\n",
        "    Args:\n",
        "        video_path: İşlenecek video dosyasının yolu\n",
        "        output_dir: Sonuçların kaydedileceği dizin\n",
        "    \"\"\"\n",
        "    # Çıktı dizinini oluştur\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Modelleri indir\n",
        "    download_models()\n",
        "\n",
        "    # Sahneleri tespit et\n",
        "    scenes = detect_scenes(video_path)\n",
        "\n",
        "    # Her sahne için oyuncuları tespit et ve takip et\n",
        "    all_players = {}\n",
        "\n",
        "    for i, scene in enumerate(scenes):\n",
        "        print(f\"\\nSahne {i+1}/{len(scenes)} işleniyor...\")\n",
        "        players = detect_and_track_players(video_path, scene, i+1)\n",
        "\n",
        "        # Her oyuncu için forma bölgesini çıkar ve numarayı tespit et\n",
        "        scene_players = {}\n",
        "\n",
        "        for player_id, frames in players.items():\n",
        "            jersey_crops = extract_jersey_region(frames)\n",
        "\n",
        "            if jersey_crops:\n",
        "                jersey_number = recognize_jersey_number(jersey_crops)\n",
        "\n",
        "                if jersey_number is not None:\n",
        "                    scene_players[player_id] = {\n",
        "                        'jersey_number': jersey_number,\n",
        "                        'frames': frames\n",
        "                    }\n",
        "\n",
        "        all_players[f\"scene_{i+1}\"] = scene_players\n",
        "\n",
        "    # Sonuçları göster ve kaydet\n",
        "    results = {}\n",
        "\n",
        "    for scene_id, players in all_players.items():\n",
        "        scene_results = {}\n",
        "\n",
        "        for player_id, player_info in players.items():\n",
        "            jersey_number = player_info['jersey_number']\n",
        "            scene_results[f\"player_{player_id}\"] = jersey_number\n",
        "\n",
        "        results[scene_id] = scene_results\n",
        "\n",
        "    # Sonuçları ekrana yazdır\n",
        "    print(\"\\n--- Forma Numarası Tanıma Sonuçları ---\")\n",
        "    for scene_id, players in results.items():\n",
        "        print(f\"\\n{scene_id}:\")\n",
        "        for player_id, jersey_number in players.items():\n",
        "            print(f\"  {player_id}: {jersey_number}\")\n",
        "\n",
        "    # Sonuçları görselleştir ve kaydet\n",
        "    visualize_results(video_path, all_players, output_dir)\n",
        "\n",
        "    return results\n",
        "\n",
        "def visualize_results(video_path, all_players, output_dir):\n",
        "    \"\"\"\n",
        "    Tespit sonuçlarını görselleştirir ve kaydeder\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Sonuç videosu için\n",
        "    result_path = os.path.join(output_dir, \"result_video.mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(result_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Her sahneyi işle\n",
        "    for scene_id, players in all_players.items():\n",
        "        # Oyuncuların görüldüğü tüm frame'leri topla\n",
        "        frame_to_players = {}\n",
        "\n",
        "        for player_id, player_info in players.items():\n",
        "            jersey_number = player_info['jersey_number']\n",
        "\n",
        "            for frame_info in player_info['frames']:\n",
        "                frame_num = frame_info['frame_num']\n",
        "                box = frame_info['box']\n",
        "\n",
        "                if frame_num not in frame_to_players:\n",
        "                    frame_to_players[frame_num] = []\n",
        "\n",
        "                frame_to_players[frame_num].append((player_id, jersey_number, box))\n",
        "\n",
        "        # Tüm frame numaralarını sırala\n",
        "        frame_nums = sorted(frame_to_players.keys())\n",
        "\n",
        "        if not frame_nums:\n",
        "            continue\n",
        "\n",
        "        # Her frame'i işle\n",
        "        for frame_num in frame_nums:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                continue\n",
        "\n",
        "            # Frame'deki tüm oyuncuları çiz\n",
        "            for player_id, jersey_number, box in frame_to_players[frame_num]:\n",
        "                x1, y1, x2, y2 = box\n",
        "\n",
        "                # Bounding box çiz\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                # Forma numarasını yazdır\n",
        "                label = f\"#{jersey_number}\"\n",
        "                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            # Sahne ID'sini yazdır\n",
        "            cv2.putText(frame, scene_id, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            # Frame'i kaydet\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Sonuç videosu kaydedildi: {result_path}\")\n",
        "\n",
        "# Ana çalıştırma bloğu\n",
        "if __name__ == \"__main__\":\n",
        "    # Google Drive'a bağlan (isteğe bağlı)\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Video yolunu belirt\n",
        "    video_path = \"/content/drive/MyDrive/videos/demo.mp4\"  # Bunu kendi video yolunuzla değiştirin\n",
        "\n",
        "    # Videoyu işle\n",
        "    results = process_video(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmRfny4HXV_a",
        "outputId": "b58b0a4b-4cf8-4a82-e061-fac4e7656dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
            "INFO:pyscenedetect:Loaded 1 video, framerate: 30.000 FPS, resolution: 852 x 480\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "YOLO modellerini indirme...\n",
            "Sahneleri tespit etme...\n",
            "Toplam 6 sahne tespit edildi.\n",
            "\n",
            "Sahne 1/6 işleniyor...\n",
            "Sahne 1 için oyuncuları tespit etme ve takip etme...\n",
            "\n",
            "0: 384x640 18 persons, 2929.5ms\n",
            "Speed: 4.2ms preprocess, 2929.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2841.5ms\n",
            "Speed: 4.3ms preprocess, 2841.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2863.0ms\n",
            "Speed: 4.0ms preprocess, 2863.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 4378.9ms\n",
            "Speed: 4.4ms preprocess, 4378.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3158.9ms\n",
            "Speed: 4.2ms preprocess, 3158.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2857.9ms\n",
            "Speed: 4.0ms preprocess, 2857.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2886.3ms\n",
            "Speed: 4.7ms preprocess, 2886.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3684.7ms\n",
            "Speed: 3.5ms preprocess, 3684.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3915.6ms\n",
            "Speed: 4.4ms preprocess, 3915.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "The shape of the mask [154] at index 0 does not match the shape of the indexed tensor [153, 6] at index 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-94148318f5d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;31m# Videoyu işle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-94148318f5d4>\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m(video_path, output_dir)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSahne {i+1}/{len(scenes)} işleniyor...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_and_track_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# Her oyuncu için forma bölgesini çıkar ve numarayı tespit et\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-94148318f5d4>\u001b[0m in \u001b[0;36mdetect_and_track_players\u001b[0;34m(video_path, scene, scene_id)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Kişileri tespit et\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperson_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sadece kişileri tespit et (class 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Tespit edilen kişilerin bounding box'larını al\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \"\"\"\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0;31m# Postprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_postprocess_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/predict.py\u001b[0m in \u001b[0;36mpostprocess\u001b[0;34m(self, preds, img, orig_imgs, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"\n\u001b[1;32m     54\u001b[0m         \u001b[0msave_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"save_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         preds = ops.non_max_suppression(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/ops.py\u001b[0m in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated, end2end, return_idxs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Check shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [154] at index 0 does not match the shape of the indexed tensor [153, 6] at index 0"
          ]
        }
      ]
    }
  ]
}