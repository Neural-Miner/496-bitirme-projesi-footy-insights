# -*- coding: utf-8 -*-
"""video-processingf-faz1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gFJmANoS5nxTNW7ST8kmAN5z-8tO6-4d

önce bu model için saniyesaniye playerların-referee+goalkeeperların konumlarının çıktısını al
sonra modeli gerekirse eğitirsin. bi önceçıktı al. bunun için classlı cellde kalmıştın. onu run ettirip. sonuçları pitche göre ya da boxa göre(eğer box pitche göreyse bir de soccernetteki ball neye göre konum belirtiyorsa ona göre çıktıyı kaydet.)

## Video Processing

## key ayarları

### Configure your API keys
    - `HF_TOKEN`.
    - `ROBOFLOW_API_KEY`.
"""

!nvidia-smi

"""## Bağımlılıklar"""

!pip install -q gdown inference-gpu
!pip install -q onnxruntime-gpu==1.18.0 --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/

"""roboflow sports"""

!pip install -q git+https://github.com/roboflow/sports.git

!pip uninstall -y supervision && pip install -q supervision>=0.23.0

import os
os.environ["ONNXRUNTIME_EXECUTION_PROVIDERS"] = "[CUDAExecutionProvider]"

"""## ball, player, goalkeeper and referee detection"""

!pip install numpy==1.25

from inference import get_model
from google.colab import userdata

ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')
PLAYER_DETECTION_MODEL_ID = "football-players-detection-3zvbc/12"
PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)

from google.colab import drive
drive.mount('/content/drive')

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_11_fraport-tav-antalyaspor_besiktas.mp4"

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

sv.plot_image(frame)

import cv2
import numpy as np
import matplotlib.pyplot as plt
import random

# Video dosyasını aç
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)

# Toplam frame sayısını al
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# Rastgele 5 frame seç
random_frames = sorted(random.sample(range(total_frames), 5))

print("Seçilen frame numaraları:", random_frames)

# Seçilen frame'leri göster
plt.figure(figsize=(15, 5))

for i, frame_number in enumerate(random_frames):
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  # Belirtilen frame'e git
    ret, frame = cap.read()  # Frame'i oku

    if ret:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV BGR formatını RGB'ye çevir
        plt.subplot(1, 5, i+1)  # 5 görselli bir subplot
        plt.imshow(frame)
        plt.title(f"Frame {frame_number}")
        plt.axis("off")
    else:
        print(f"{frame_number} numaralı frame alınamadı.")

cap.release()
plt.show()

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

box_annotator = sv.BoxAnnotator(
    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000')
)

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
detections = sv.Detections.from_inference(result)

labels = [
    f"{class_name} {confidence:.2f}"
    for class_name, confidence
    in zip(detections['class_name'], detections.confidence)
]

annotated_frame = frame.copy()
annotated_frame = box_annotator.annotate(
    scene=annotated_frame,
    detections=detections)
annotated_frame = label_annotator.annotate(
    scene=annotated_frame,
    detections=detections,
    labels=labels)

sv.plot_image(annotated_frame)

import supervision as sv
import random
import cv2
import matplotlib.pyplot as plt

# Video dosyasını belirle
SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

# Anotasyonlar için renkler ve stiller
box_annotator = sv.BoxAnnotator(
    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000')
)

# Videoyu aç ve toplam frame sayısını öğren
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# Rastgele 5 farklı frame seç
random_frames = sorted(random.sample(range(total_frames), 5))
print("Seçilen frame numaraları:", random_frames)

# Seçilen frame'leri işle ve göster
plt.figure(figsize=(15, 10))

for i, frame_number in enumerate(random_frames):
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  # Belirtilen frame'e git
    ret, frame = cap.read()  # Frame'i oku

    if ret:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV'den gelen frame'i RGB'ye çevir

        # Oyuncu tespiti modeli ile frame üzerinde inference yap
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)

        # Etiketleri oluştur
        labels = [
            f"{class_name} {confidence:.2f}"
            for class_name, confidence
            in zip(detections['class_name'], detections.confidence)
        ]

        # Anotasyonları uygula
        annotated_frame = frame.copy()
        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)
        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)

        # Görüntüyü subplot içinde göster
        plt.subplot(2, 3, i+1)  # 2 satır, 3 sütunluk grid şeklinde düzenler
        plt.imshow(annotated_frame)
        plt.title(f"Frame {frame_number}")
        plt.axis("off")
    else:
        print(f"{frame_number} numaralı frame alınamadı.")

cap.release()
plt.tight_layout()
plt.show()

"""## video game style visualization"""

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0

ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
detections = sv.Detections.from_inference(result)

ball_detections = detections[detections.class_id == BALL_ID]
ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

all_detections = detections[detections.class_id != BALL_ID]
all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
all_detections.class_id -= 1

annotated_frame = frame.copy()
annotated_frame = ellipse_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections)
annotated_frame = triangle_annotator.annotate(
    scene=annotated_frame,
    detections=ball_detections)

sv.plot_image(annotated_frame)

import supervision as sv
import cv2
import matplotlib.pyplot as plt

# Ball ID
BALL_ID = 0

# Anotasyon tanımları
ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

# Videoyu tekrar aç
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)

# Seçilen frame'leri işle ve göster
plt.figure(figsize=(15, 10))

for i, frame_number in enumerate(random_frames):  # Önceki hücrede seçilen frame'leri kullanıyoruz
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  # Belirtilen frame'e git
    ret, frame = cap.read()  # Frame'i oku

    if ret:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV'den gelen frame'i RGB'ye çevir

        # Oyuncu tespiti modeli ile frame üzerinde inference yap
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)

        # Top ve diğer nesneleri ayır
        ball_detections = detections[detections.class_id == BALL_ID]
        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)  # Top için kutuyu genişlet

        all_detections = detections[detections.class_id != BALL_ID]
        all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
        all_detections.class_id -= 1  # ID'leri yeniden düzenle

        # Anotasyonları uygula
        annotated_frame = frame.copy()
        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)
        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)

        # Görüntüyü subplot içinde göster
        plt.subplot(2, 3, i+1)  # 2 satır, 3 sütun düzeninde görüntüleri yerleştirir
        plt.imshow(annotated_frame)
        plt.title(f"Frame {frame_number}")
        plt.axis("off")
    else:
        print(f"{frame_number} numaralı frame alınamadı.")

cap.release()
plt.tight_layout()
plt.show()

"""## player tracking"""

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0

ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000'),
    text_position=sv.Position.BOTTOM_CENTER
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

tracker = sv.ByteTrack()
tracker.reset()

# Açmak istediğiniz spesifik frame numarası
FRAME_NUMBER = 1200

# OpenCV ile videoyu aç
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)

# İlgili frame numarasına git
cap.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUMBER)

# Frame'i oku
ret, frame = cap.read()

# Frame başarıyla alındıysa devam et
if ret:
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV BGR formatını RGB'ye çevir
    sv.plot_image(frame)  # Supervision ile frame'i göster
else:
    print(f"{FRAME_NUMBER}. frame alınamadı. Video dosyası eksik veya bozuk olabilir.")

result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
detections = sv.Detections.from_inference(result)

ball_detections = detections[detections.class_id == BALL_ID]
ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

all_detections = detections[detections.class_id != BALL_ID]
all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
all_detections.class_id -= 1
all_detections = tracker.update_with_detections(detections=all_detections)

labels = [
    f"#{tracker_id}"
    for tracker_id
    in all_detections.tracker_id
]

annotated_frame = frame.copy()
annotated_frame = ellipse_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections)
annotated_frame = label_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections,
    labels=labels)
annotated_frame = triangle_annotator.annotate(
    scene=annotated_frame,
    detections=ball_detections)

sv.plot_image(annotated_frame)

import supervision as sv
import random
import cv2
import matplotlib.pyplot as plt

# Video dosyası
SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0  # Topun sınıf ID'si

# Anotasyon tanımları
ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000'),
    text_position=sv.Position.BOTTOM_CENTER
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

# Tracker başlat
tracker = sv.ByteTrack()
tracker.reset()

# Videoyu aç ve toplam frame sayısını öğren
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# Daha önce seçilmiş random frame numaraları (Önceki hücrede tanımlanmış olmalı)
print("Önceki hücrede seçilen frame numaraları:", random_frames)

# Seçilen frame'leri işle ve göster
plt.figure(figsize=(15, 10))

for i, frame_number in enumerate(random_frames):  # Önceki hücrede belirlenen random frame'ler
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  # Belirtilen frame'e git
    ret, frame = cap.read()  # Frame'i oku

    if ret:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV formatını RGB'ye çevir

        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)

        ball_detections = detections[detections.class_id == BALL_ID]
        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

        all_detections = detections[detections.class_id != BALL_ID]
        all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
        all_detections.class_id -= 1
        all_detections = tracker.update_with_detections(detections=all_detections)

        labels = [
            f"#{tracker_id}"
            for tracker_id
            in all_detections.tracker_id
        ]

        annotated_frame = frame.copy()
        annotated_frame = ellipse_annotator.annotate(
            scene=annotated_frame,
            detections=all_detections)
        annotated_frame = label_annotator.annotate(
            scene=annotated_frame,
            detections=all_detections,
            labels=labels)
        annotated_frame = triangle_annotator.annotate(
            scene=annotated_frame,
            detections=ball_detections)

        sv.plot_image(annotated_frame)

cap.release()
plt.tight_layout()
plt.show()

import supervision as sv
import cv2

# Video dosyanız
SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0

# Çıktı videosunun kaydedileceği dosya
OUTPUT_VIDEO_PATH = "/content/tracker_output_5min.mp4"

# VideoCapture ile videoyu aç
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)

# Video özelliklerini al
fps = int(cap.get(cv2.CAP_PROP_FPS))  # FPS değerini al
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Videodaki toplam frame sayısı

# İlk 5 dakika için frame sınırı
max_frames = min(fps * 60 * 2, total_frames)  # 5 dakika * 60 saniye * FPS

# OpenCV VideoWriter ile çıktıyı kaydetme
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4 formatı için codec
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))

# Tracker başlat
tracker = sv.ByteTrack()
tracker.reset()

# Anotasyon tanımları
ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000'),
    text_position=sv.Position.BOTTOM_CENTER
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

# Frame'leri sırayla işle (İlk 5 dakika için)
frame_count = 0
while cap.isOpened() and frame_count < max_frames:
    ret, frame = cap.read()
    if not ret:
        break  # Video bitti

    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV frame formatını RGB'ye çevir

    # Nesne tespiti modeli ile frame üzerinde işlem yap
    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)

    # Top ve diğer nesneleri ayır
    ball_detections = detections[detections.class_id == BALL_ID]
    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

    all_detections = detections[detections.class_id != BALL_ID]
    all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
    all_detections.class_id -= 1
    all_detections = tracker.update_with_detections(detections=all_detections)

    # Tracker ID etiketlerini oluştur
    labels = [
        f"#{tracker_id}"
        for tracker_id in all_detections.tracker_id
    ]

    # Anotasyonları uygula
    annotated_frame = frame.copy()
    annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)
    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=all_detections, labels=labels)
    annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)

    # Frame'i RGB'den BGR'ye çevir (OpenCV için)
    annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)

    # Frame'i video dosyasına kaydet
    out.write(annotated_frame)

    frame_count += 1  # Frame sayısını artır

# Kaynakları serbest bırak
cap.release()
out.release()
cv2.destroyAllWindows()

print(f"İlk 5 dakikanın işlendiği video kaydedildi: {OUTPUT_VIDEO_PATH}")

"""OBJE DETECTION + CLUSTERING + NUMBER RECOGNITION and endly TRACKING

## split players into teams

![football AI diagram](https://media.roboflow.com/notebooks/examples/football-ai-team-clustering.png)
"""

from tqdm import tqdm

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
PLAYER_ID = 2
STRIDE = 30

frame_generator = sv.get_video_frames_generator(
    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)

crops = []
for frame in tqdm(frame_generator, desc='collecting crops'):
    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)
    detections = detections.with_nms(threshold=0.5, class_agnostic=True)
    detections = detections[detections.class_id == PLAYER_ID]
    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]
    crops += players_crops

"""**Note:** croplar"""

sv.plot_images_grid(crops[:100], grid_size=(10, 10))

"""**Note:**  [SigLIP](https://huggingface.co/docs/transformers/en/model_doc/siglip)"""

import torch
from transformers import AutoProcessor, SiglipVisionModel

SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)
EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)

import numpy as np
from more_itertools import chunked

BATCH_SIZE = 32

crops = [sv.cv2_to_pillow(crop) for crop in crops]
batches = chunked(crops, BATCH_SIZE)
data = []
with torch.no_grad():
    for batch in tqdm(batches, desc='embedding extraction'):
        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors="pt").to(DEVICE)
        outputs = EMBEDDINGS_MODEL(**inputs)
        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()
        data.append(embeddings)

data = np.concatenate(data)

"""**Note:** Using [UMAP](https://github.com/lmcinnes/umap), we project our embeddings from `(N, 768)` to `(N, 3)` and then perform a two-cluster division using [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."""

import umap
from sklearn.cluster import KMeans

REDUCER = umap.UMAP(n_components=3)
CLUSTERING_MODEL = KMeans(n_clusters=2)

projections = REDUCER.fit_transform(data)
clusters = CLUSTERING_MODEL.fit_predict(projections)

import plotly.graph_objects as go
import numpy as np
from typing import Dict, List
from IPython.core.display import display, HTML
from PIL import Image
import base64
from io import BytesIO


def pil_image_to_data_uri(image: Image.Image) -> str:
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return f"data:image/png;base64,{img_str}"


def display_projections(
    labels: np.ndarray,
    projections: np.ndarray,
    images: List[Image.Image],
    show_legend: bool = False,
    show_markers_with_text: bool = True
) -> None:
    image_data_uris = {f"image_{i}": pil_image_to_data_uri(image) for i, image in enumerate(images)}
    image_ids = np.array([f"image_{i}" for i in range(len(images))])

    unique_labels = np.unique(labels)
    traces = []
    for unique_label in unique_labels:
        mask = labels == unique_label
        customdata_masked = image_ids[mask]
        trace = go.Scatter3d(
            x=projections[mask][:, 0],
            y=projections[mask][:, 1],
            z=projections[mask][:, 2],
            mode='markers+text' if show_markers_with_text else 'markers',
            text=labels[mask],
            customdata=customdata_masked,
            name=str(unique_label),
            marker=dict(size=8),
            hovertemplate="<b>class: %{text}</b><br>image ID: %{customdata}<extra></extra>"
        )
        traces.append(trace)

    fig = go.Figure(data=traces)
    fig.update_layout(
        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),
        width=1000,
        height=1000,
        showlegend=show_legend
    )

    plotly_div = fig.to_html(full_html=False, include_plotlyjs=False, div_id="scatter-plot-3d")

    javascript_code = f"""
    <script>
        function displayImage(imageId) {{
            var imageElement = document.getElementById('image-display');
            var placeholderText = document.getElementById('placeholder-text');
            var imageDataURIs = {image_data_uris};
            imageElement.src = imageDataURIs[imageId];
            imageElement.style.display = 'block';
            placeholderText.style.display = 'none';
        }}

        var chartElement = document.getElementById('scatter-plot-3d');

        chartElement.on('plotly_click', function(data) {{
            var customdata = data.points[0].customdata;
            displayImage(customdata);
        }});
    </script>
    """

    html_template = f"""
    <!DOCTYPE html>
    <html>
        <head>
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <style>
                #image-container {{
                    position: fixed;
                    top: 0;
                    left: 0;
                    width: 200px;
                    height: 200px;
                    padding: 5px;
                    border: 1px solid #ccc;
                    background-color: white;
                    z-index: 1000;
                    box-sizing: border-box;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    text-align: center;
                }}
                #image-display {{
                    width: 100%;
                    height: 100%;
                    object-fit: contain;
                }}
            </style>
        </head>
        <body>
            {plotly_div}
            <div id="image-container">
                <img id="image-display" src="" alt="Selected image" style="display: none;" />
                <p id="placeholder-text">Click on a data entry to display an image</p>
            </div>
            {javascript_code}
        </body>
    </html>
    """

    display(HTML(html_template))

display_projections(clusters, projections, crops)

"""**Note:**SigLIP, UMAP ve KMeans combo"""

import supervision as sv
from tqdm import tqdm
from sports.common.team import TeamClassifier

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
PLAYER_ID = 2
STRIDE = 30

frame_generator = sv.get_video_frames_generator(
    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)

crops = []
for frame in tqdm(frame_generator, desc='collecting crops'):
    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)
    players_detections = detections[detections.class_id == PLAYER_ID]
    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]
    crops += players_crops

team_classifier = TeamClassifier(device="cuda")
team_classifier.fit(crops)

"""**Note:** kaleci en yakın 3 oyuncu takımına göre takım atanır"""

import numpy as np
import supervision as sv

def resolve_goalkeepers_team_id(
    players: sv.Detections,
    goalkeepers: sv.Detections
) -> np.ndarray:
    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)
    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)
    goalkeepers_team_id = []
    for goalkeeper_xy in goalkeepers_xy:
        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)
        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)
        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)

    return np.array(goalkeepers_team_id)

"""#### Tracking with jersey number

OCR Başlatıcı ve Mapping Sözlüğü (setup)
"""

import json
import os
import cv2
from collections import defaultdict, Counter

ocr_reader = easyocr.Reader(['en'], gpu=True)
os.makedirs("debug_crops", exist_ok=True)

# Tracker ID → Forma numarası eşleşmeleri
tracker_id_to_jersey_number = {}

# Ardışık OCR sonuçları: tracker_id → liste
ocr_results_buffer = defaultdict(list)

# Daha önce kaydedilen forma numaraları varsa yükle
JERSEY_MAPPING_PATH = "jersey_mapping.json"
if os.path.exists(JERSEY_MAPPING_PATH):
    with open(JERSEY_MAPPING_PATH, "r") as f:
        tracker_id_to_jersey_number = {
            int(k): int(v) for k, v in json.load(f).items()
        }

# Üst vücut bölgesini croplayan fonksiyon
def crop_upper_body(xyxy, frame, expand_px=30):
    x1, y1, x2, y2 = map(int, xyxy)
    width = x2 - x1
    height = y2 - y1

    # Tüm üst gövdeyi alma — üst + bir miktar bel kısmı
    y2_new = y1 + int(height * 0.65)

    x1 = max(0, x1 - expand_px)
    y1 = max(0, y1 - expand_px)
    x2 = min(frame.shape[1], x2 + expand_px)
    y2_new = min(frame.shape[0], y2_new + expand_px)

    return frame[y1:y2_new, x1:x2]

# OCR ile forma numarası okuma
def get_jersey_number_from_crop(crop_image):
    results = ocr_reader.readtext(crop_image, allowlist='0123456789')
    for bbox, text, confidence in results:
        text_clean = text.strip().replace(" ", "")
        if text_clean.isdigit():
            number = int(text_clean)
            if 0 < number <= 99:
                return number
    return None

def save_crop_with_label(crop, path, label):
    import cv2
    font = cv2.FONT_HERSHEY_SIMPLEX
    labeled = crop.copy()
    cv2.putText(labeled, label, (5, 15), font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
    cv2.imwrite(path, labeled)

def preprocess_for_ocr(image):
    import cv2
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Kontrast ve keskinlik artırma
    sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    sharpened = cv2.filter2D(gray, -1, sharpen_kernel)
    # Histogram eşitleme
    equalized = cv2.equalizeHist(sharpened)
    return equalized

import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
print(f"Current CUDA device: {torch.cuda.current_device()}")

import supervision as sv
import numpy as np
from tqdm import tqdm
from sports.common.team import TeamClassifier

# Video Kaynağı
SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

# Nesne Kimlikleri
BALL_ID = 0
GOALKEEPER_ID = 1
PLAYER_ID = 2
REFEREE_ID = 3

# Frame alma sıklığı
STRIDE = 30
frame_counter = 0  # Frame numarasını takip et

# Model ve Tracker Tanımlama
tracker = sv.ByteTrack()
tracker.reset()
team_classifier = TeamClassifier(device="cuda")

# Modelin eğitildiğini kontrol etmek için değişken
is_team_classifier_trained = False  # Modelin eğitilip eğitilmediğini takip et

# Video karelerini almak için generator
frame_generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH, stride=STRIDE)

for frame in tqdm(frame_generator, desc="Processing video"):
    frame_counter += STRIDE  # Frame numarasını güncelle

    # Oyuncu Algılama Modelini Çalıştır
    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)

    # Eğer hiçbir nesne tespit edilmediyse, ekrana frame numarası yazdır
    if len(detections) == 0:
        print(f"⚠️ Warning: No objects detected at frame {frame_counter}")

        # Boş bir Detections nesnesi oluştur
        all_detections = sv.Detections(
            xyxy=np.empty((0, 4)),
            class_id=np.empty((0,)),
            confidence=np.empty((0,)),
            tracker_id=np.empty((0,))
        )
    else:
        # Top tespitlerini ve diğer objeleri ayır
        ball_detections = detections[detections.class_id == BALL_ID]
        all_detections = detections[detections.class_id != BALL_ID]

        # Eğer oyuncu, hakem veya kaleci yoksa sadece tracking devam etsin
        if len(all_detections) > 0:
            all_detections = tracker.update_with_detections(detections=all_detections)

        # Oyuncu, kaleci ve hakemleri ayır
        players_detections = all_detections[all_detections.class_id == PLAYER_ID]
        # Forma numarası tespiti yapılmamış oyuncular için OCR çalıştır
        for i, tracker_id in enumerate(players_detections.tracker_id):
          if tracker_id not in tracker_id_to_jersey_number:
              crop = crop_upper_body(players_detections.xyxy[i], frame)

              # CROP’U DEBUG İÇİN KAYDET
              debug_path = f"debug_crops/frame{frame_counter}_id{tracker_id}.jpg"
              save_crop_with_label(crop, debug_path, f"F{frame_counter} ID:{tracker_id}")


              # OCR işlemi
              processed_crop = preprocess_for_ocr(crop)
              jersey_number = get_jersey_number_from_crop(processed_crop)
              if jersey_number is not None:
                  ocr_results_buffer[tracker_id].append(jersey_number)

              # OCR Sonuçlarını değerlendirme
              if len(ocr_results_buffer[tracker_id]) >= 5:
                  most_common = Counter(ocr_results_buffer[tracker_id]).most_common(1)[0]
                  number, count = most_common
                  if count >= 2:
                      tracker_id_to_jersey_number[tracker_id] = number
                      print(f"✅ Jersey #{number} assigned to Tracker ID {tracker_id}")
                  else:
                      print(f"🔍 OCR results for {tracker_id}: {ocr_results_buffer[tracker_id]}")
              else:
                  print(f"🔍 Buffering OCR for Tracker ID {tracker_id}: {ocr_results_buffer[tracker_id]}")


        goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]
        referees_detections = all_detections[all_detections.class_id == REFEREE_ID]

        # Oyuncuların takımını belirle
        if len(players_detections) > 0:
            players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]

            # Eğer crop edilen oyuncu görüntüleri varsa, modelin eğitilip eğitilmediğini kontrol et
            if len(players_crops) > 1:
                if not is_team_classifier_trained:
                    print(f"🔄 Training team classifier with {len(players_crops)} samples...")
                    team_classifier.fit(players_crops)
                    is_team_classifier_trained = True  # Modelin eğitildiğini işaretle

                # Model eğitildiyse tahmin yap
                if is_team_classifier_trained:
                    players_detections.class_id = team_classifier.predict(players_crops)
            else:
                print(f"⚠️ Warning: Skipping team classification at frame {frame_counter} (Not enough data)")

        # Kalecilerin takımını belirle
        if len(goalkeepers_detections) > 0:
            goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)

        # Hakemleri ayrı kategoriye al
        referees_detections.class_id -= 1

        # Tespitleri birleştir
        all_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])

    # Takip ID'lerini ekleyerek etiketleme (Boşluk kontrolü eklendi)
    labels = [
      f"#{tracker_id_to_jersey_number.get(tracker_id, '??')}"
      for tracker_id in all_detections.tracker_id
    ] if len(all_detections) > 0 else []


    # Görselleştirme
    annotated_frame = frame.copy()

    if len(all_detections) > 0:
        ellipse_annotator = sv.EllipseAnnotator(
            color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
            thickness=2
        )
        label_annotator = sv.LabelAnnotator(
            color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
            text_color=sv.Color.from_hex('#000000'),
            text_position=sv.Position.BOTTOM_CENTER
        )
        triangle_annotator = sv.TriangleAnnotator(
            color=sv.Color.from_hex('#FFD700'),
            base=25,
            height=21,
            outline_thickness=1
        )

        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)
        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=all_detections, labels=labels)
        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)

    # Frame'yi göster
    sv.plot_image(annotated_frame)

print("✅ Video Processing Completed Successfully!")

# Forma numarası eşleşmelerini kaydet
with open(JERSEY_MAPPING_PATH, "w") as f:
    json.dump(tracker_id_to_jersey_number, f)

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0
GOALKEEPER_ID = 1
PLAYER_ID = 2
REFEREE_ID = 3

ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000'),
    text_position=sv.Position.BOTTOM_CENTER
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=25,
    height=21,
    outline_thickness=1
)

tracker = sv.ByteTrack()
tracker.reset()

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
detections = sv.Detections.from_inference(result)

ball_detections = detections[detections.class_id == BALL_ID]
ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

all_detections = detections[detections.class_id != BALL_ID]
all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
all_detections = tracker.update_with_detections(detections=all_detections)

goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]
players_detections = all_detections[all_detections.class_id == PLAYER_ID]
referees_detections = all_detections[all_detections.class_id == REFEREE_ID]

players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]
players_detections.class_id = team_classifier.predict(players_crops)

goalkeepers_detections.class_id = resolve_goalkeepers_team_id(
    players_detections, goalkeepers_detections)

referees_detections.class_id -= 1

all_detections = sv.Detections.merge([
    players_detections, goalkeepers_detections, referees_detections])

labels = [
    f"#{tracker_id}"
    for tracker_id
    in all_detections.tracker_id
]

all_detections.class_id = all_detections.class_id.astype(int)

annotated_frame = frame.copy()
annotated_frame = ellipse_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections)
annotated_frame = label_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections,
    labels=labels)
annotated_frame = triangle_annotator.annotate(
    scene=annotated_frame,
    detections=ball_detections)

sv.plot_image(annotated_frame)

"""## pitch keypoint detection"""

from inference import get_model
from google.colab import userdata

ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')
FIELD_DETECTION_MODEL_ID = "football-field-detection-f07vi/14"
FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

vertex_annotator = sv.VertexAnnotator(
    color=sv.Color.from_hex('#FF1493'),
    radius=8)

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
key_points = sv.KeyPoints.from_inference(result)

annotated_frame = frame.copy()
annotated_frame = vertex_annotator.annotate(
    scene=annotated_frame,
    key_points=key_points)

sv.plot_image(annotated_frame)

import supervision as sv
import random
import cv2

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

# Video capture aç
cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
print(f"Toplam frame sayısı: {total_frames}")

# Rastgele bir frame indeksi seç
random_frame_index = random.randint(0, total_frames - 1)
print(f"Seçilen rastgele frame indeksi: {random_frame_index}")

# Seçilen frame'e git
cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_index)
ret, frame = cap.read()
cap.release()

if ret:
    # OpenCV BGR -> RGB dönüşümü
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Vertex annotator oluştur
    vertex_annotator = sv.VertexAnnotator(
        color=sv.Color.from_hex('#FF1493'),
        radius=8)

    # Modeli çalıştır
    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    key_points = sv.KeyPoints.from_inference(result)

    # Frame'i annotate et
    annotated_frame = frame.copy()
    annotated_frame = vertex_annotator.annotate(
        scene=annotated_frame,
        key_points=key_points)

    # Sonucu göster
    sv.plot_image(annotated_frame)
else:
    print("Frame okunamadı!")

"""**Note:** Notice that some of the keypoints we detected are in incorrect locations. These are keypoints with a low confidence level. Let's filter out these keypoints and keep only the ones the model is confident about.

## filter low confidence keypoints
"""

import supervision as sv

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

vertex_annotator = sv.VertexAnnotator(
    color=sv.Color.from_hex('#FF1493'),
    radius=8)

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)
frame = next(frame_generator)

result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
key_points = sv.KeyPoints.from_inference(result)

filter = key_points.confidence[0] > 0.5
frame_reference_points = key_points.xy[0][filter]
frame_reference_key_points = sv.KeyPoints(
    xy=frame_reference_points[np.newaxis, ...])

annotated_frame = frame.copy()
annotated_frame = vertex_annotator.annotate(
    scene=annotated_frame,
    key_points=frame_reference_key_points)

sv.plot_image(annotated_frame)

import supervision as sv
import numpy as np
import random

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

# Video bilgilerini al
video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)
total_frames = video_info.total_frames
print(f"Toplam frame sayısı: {total_frames}")

# Rastgele bir frame indeksi seç
random_frame_index = random.randint(0, total_frames - 1)
print(f"Seçilen rastgele frame indeksi: {random_frame_index}")

vertex_annotator = sv.VertexAnnotator(
    color=sv.Color.from_hex('#FF1493'),
    radius=8)

# Rastgele seçilen frame'den başla
frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=random_frame_index)
frame = next(frame_generator)

# Modeli çalıştır
result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
key_points = sv.KeyPoints.from_inference(result)

# Güven değeri 0.5'ten büyük noktaları filtrele
filter = key_points.confidence[0] > 0.5
frame_reference_points = key_points.xy[0][filter]
frame_reference_key_points = sv.KeyPoints(
    xy=frame_reference_points[np.newaxis, ...])

# Frame'i annotate et
annotated_frame = frame.copy()
annotated_frame = vertex_annotator.annotate(
    scene=annotated_frame,
    key_points=frame_reference_key_points)

# Sonucu göster
sv.plot_image(annotated_frame)

"""## project pitch lines on frame

**Note:** The [sports](https://github.com/roboflow/sports) repository  [`SoccerPitchConfiguration`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/configs/soccer.py#L6)
"""

from sports.annotators.soccer import draw_pitch
from sports.configs.soccer import SoccerPitchConfiguration

CONFIG = SoccerPitchConfiguration()

annotated_frame = draw_pitch(CONFIG)

sv.plot_image(annotated_frame)

"""**Note:** It's time to utilize the keypoint pairs located on the camera perspective plane and the football pitch plane. The [sports](https://github.com/roboflow/sports) repository includes a [`ViewTransformer`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/common/view.py#L7), which employs homography for perspective transformation."""

import numpy as np
import supervision as sv
from sports.common.view import ViewTransformer

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"

edge_annotator = sv.EdgeAnnotator(
    color=sv.Color.from_hex('#00BFFF'),
    thickness=2, edges=CONFIG.edges)
vertex_annotator = sv.VertexAnnotator(
    color=sv.Color.from_hex('#FF1493'),
    radius=8)
vertex_annotator_2 = sv.VertexAnnotator(
    color=sv.Color.from_hex('#00BFFF'),
    radius=8)

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)
frame = next(frame_generator)

result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
key_points = sv.KeyPoints.from_inference(result)

filter = key_points.confidence[0] > 0.5
frame_reference_points = key_points.xy[0][filter]
frame_reference_key_points = sv.KeyPoints(
    xy=frame_reference_points[np.newaxis, ...])

pitch_reference_points = np.array(CONFIG.vertices)[filter]

transformer = ViewTransformer(
    source=pitch_reference_points,
    target=frame_reference_points
)

pitch_all_points = np.array(CONFIG.vertices)
frame_all_points = transformer.transform_points(points=pitch_all_points)

frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])

annotated_frame = frame.copy()
annotated_frame = edge_annotator.annotate(
    scene=annotated_frame,
    key_points=frame_all_key_points)
annotated_frame = vertex_annotator_2.annotate(
    scene=annotated_frame,
    key_points=frame_all_key_points)
annotated_frame = vertex_annotator.annotate(
    scene=annotated_frame,
    key_points=frame_reference_key_points)

sv.plot_image(annotated_frame)

"""## project ball, players and referies on pitch"""

import supervision as sv
from tqdm import tqdm
from sports.common.team import TeamClassifier

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
PLAYER_ID = 2
STRIDE = 30

frame_generator = sv.get_video_frames_generator(
    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)

crops = []
for frame in tqdm(frame_generator, desc='collecting crops'):
    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)
    players_detections = detections[detections.class_id == PLAYER_ID]
    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]
    crops += players_crops

team_classifier = TeamClassifier(device="cuda")
team_classifier.fit(crops)

import cv2
from typing import Optional

def draw_pitch_voronoi_diagram_2(
    config: SoccerPitchConfiguration,
    team_1_xy: np.ndarray,
    team_2_xy: np.ndarray,
    team_1_color: sv.Color = sv.Color.RED,
    team_2_color: sv.Color = sv.Color.WHITE,
    opacity: float = 0.5,
    padding: int = 50,
    scale: float = 0.1,
    pitch: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Draws a Voronoi diagram on a soccer pitch representing the control areas of two
    teams with smooth color transitions.

    Args:
        config (SoccerPitchConfiguration): Configuration object containing the
            dimensions and layout of the pitch.
        team_1_xy (np.ndarray): Array of (x, y) coordinates representing the positions
            of players in team 1.
        team_2_xy (np.ndarray): Array of (x, y) coordinates representing the positions
            of players in team 2.
        team_1_color (sv.Color, optional): Color representing the control area of
            team 1. Defaults to sv.Color.RED.
        team_2_color (sv.Color, optional): Color representing the control area of
            team 2. Defaults to sv.Color.WHITE.
        opacity (float, optional): Opacity of the Voronoi diagram overlay.
            Defaults to 0.5.
        padding (int, optional): Padding around the pitch in pixels.
            Defaults to 50.
        scale (float, optional): Scaling factor for the pitch dimensions.
            Defaults to 0.1.
        pitch (Optional[np.ndarray], optional): Existing pitch image to draw the
            Voronoi diagram on. If None, a new pitch will be created. Defaults to None.

    Returns:
        np.ndarray: Image of the soccer pitch with the Voronoi diagram overlay.
    """
    if pitch is None:
        pitch = draw_pitch(
            config=config,
            padding=padding,
            scale=scale
        )

    scaled_width = int(config.width * scale)
    scaled_length = int(config.length * scale)

    voronoi = np.zeros_like(pitch, dtype=np.uint8)

    team_1_color_bgr = np.array(team_1_color.as_bgr(), dtype=np.uint8)
    team_2_color_bgr = np.array(team_2_color.as_bgr(), dtype=np.uint8)

    y_coordinates, x_coordinates = np.indices((
        scaled_width + 2 * padding,
        scaled_length + 2 * padding
    ))

    y_coordinates -= padding
    x_coordinates -= padding

    def calculate_distances(xy, x_coordinates, y_coordinates):
        return np.sqrt((xy[:, 0][:, None, None] * scale - x_coordinates) ** 2 +
                       (xy[:, 1][:, None, None] * scale - y_coordinates) ** 2)

    distances_team_1 = calculate_distances(team_1_xy, x_coordinates, y_coordinates)
    distances_team_2 = calculate_distances(team_2_xy, x_coordinates, y_coordinates)

    min_distances_team_1 = np.min(distances_team_1, axis=0)
    min_distances_team_2 = np.min(distances_team_2, axis=0)

    # Increase steepness of the blend effect
    steepness = 15  # Increased steepness for sharper transition
    distance_ratio = min_distances_team_2 / np.clip(min_distances_team_1 + min_distances_team_2, a_min=1e-5, a_max=None)
    blend_factor = np.tanh((distance_ratio - 0.5) * steepness) * 0.5 + 0.5

    # Create the smooth color transition
    for c in range(3):  # Iterate over the B, G, R channels
        voronoi[:, :, c] = (blend_factor * team_1_color_bgr[c] +
                            (1 - blend_factor) * team_2_color_bgr[c]).astype(np.uint8)

    overlay = cv2.addWeighted(voronoi, opacity, pitch, 1 - opacity, 0)

    return overlay

import supervision as sv
from sports.annotators.soccer import (
    draw_pitch,
    draw_points_on_pitch,
    draw_pitch_voronoi_diagram
)

SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
BALL_ID = 0
GOALKEEPER_ID = 1
PLAYER_ID = 2
REFEREE_ID = 3

ellipse_annotator = sv.EllipseAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    thickness=2
)
label_annotator = sv.LabelAnnotator(
    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),
    text_color=sv.Color.from_hex('#000000'),
    text_position=sv.Position.BOTTOM_CENTER
)
triangle_annotator = sv.TriangleAnnotator(
    color=sv.Color.from_hex('#FFD700'),
    base=20, height=17
)

tracker = sv.ByteTrack()
tracker.reset()

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(frame_generator)

# ball, goalkeeper, player, referee detection

result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
detections = sv.Detections.from_inference(result)

ball_detections = detections[detections.class_id == BALL_ID]
ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

all_detections = detections[detections.class_id != BALL_ID]
all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
all_detections = tracker.update_with_detections(detections=all_detections)

goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]
players_detections = all_detections[all_detections.class_id == PLAYER_ID]
referees_detections = all_detections[all_detections.class_id == REFEREE_ID]

# team assignment

players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]
players_detections.class_id = team_classifier.predict(players_crops)

goalkeepers_detections.class_id = resolve_goalkeepers_team_id(
    players_detections, goalkeepers_detections)

referees_detections.class_id -= 1

all_detections = sv.Detections.merge([
    players_detections, goalkeepers_detections, referees_detections])

# frame visualization

labels = [
    f"#{tracker_id}"
    for tracker_id
    in all_detections.tracker_id
]

all_detections.class_id = all_detections.class_id.astype(int)

annotated_frame = frame.copy()
annotated_frame = ellipse_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections)
annotated_frame = label_annotator.annotate(
    scene=annotated_frame,
    detections=all_detections,
    labels=labels)
annotated_frame = triangle_annotator.annotate(
    scene=annotated_frame,
    detections=ball_detections)

sv.plot_image(annotated_frame)

players_detections = sv.Detections.merge([
    players_detections, goalkeepers_detections
])

# detect pitch key points

result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
key_points = sv.KeyPoints.from_inference(result)

# project ball, players and referies on pitch

filter = key_points.confidence[0] > 0.5
frame_reference_points = key_points.xy[0][filter]
pitch_reference_points = np.array(CONFIG.vertices)[filter]

transformer = ViewTransformer(
    source=frame_reference_points,
    target=pitch_reference_points
)

frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)

players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
pitch_players_xy = transformer.transform_points(points=players_xy)

referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
pitch_referees_xy = transformer.transform_points(points=referees_xy)

# visualize video game-style radar view

annotated_frame = draw_pitch(CONFIG)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_ball_xy,
    face_color=sv.Color.WHITE,
    edge_color=sv.Color.BLACK,
    radius=10,
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_players_xy[players_detections.class_id == 0],
    face_color=sv.Color.from_hex('00BFFF'),
    edge_color=sv.Color.BLACK,
    radius=16,
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_players_xy[players_detections.class_id == 1],
    face_color=sv.Color.from_hex('FF1493'),
    edge_color=sv.Color.BLACK,
    radius=16,
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_referees_xy,
    face_color=sv.Color.from_hex('FFD700'),
    edge_color=sv.Color.BLACK,
    radius=16,
    pitch=annotated_frame)

sv.plot_image(annotated_frame)

# visualize voronoi diagram

annotated_frame = draw_pitch(CONFIG)
annotated_frame = draw_pitch_voronoi_diagram(
    config=CONFIG,
    team_1_xy=pitch_players_xy[players_detections.class_id == 0],
    team_2_xy=pitch_players_xy[players_detections.class_id == 1],
    team_1_color=sv.Color.from_hex('00BFFF'),
    team_2_color=sv.Color.from_hex('FF1493'),
    pitch=annotated_frame)

sv.plot_image(annotated_frame)

# visualize voronoi diagram with blend

annotated_frame = draw_pitch(
    config=CONFIG,
    background_color=sv.Color.WHITE,
    line_color=sv.Color.BLACK
)
annotated_frame = draw_pitch_voronoi_diagram_2(
    config=CONFIG,
    team_1_xy=pitch_players_xy[players_detections.class_id == 0],
    team_2_xy=pitch_players_xy[players_detections.class_id == 1],
    team_1_color=sv.Color.from_hex('00BFFF'),
    team_2_color=sv.Color.from_hex('FF1493'),
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_ball_xy,
    face_color=sv.Color.WHITE,
    edge_color=sv.Color.WHITE,
    radius=8,
    thickness=1,
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_players_xy[players_detections.class_id == 0],
    face_color=sv.Color.from_hex('00BFFF'),
    edge_color=sv.Color.WHITE,
    radius=16,
    thickness=1,
    pitch=annotated_frame)
annotated_frame = draw_points_on_pitch(
    config=CONFIG,
    xy=pitch_players_xy[players_detections.class_id == 1],
    face_color=sv.Color.from_hex('FF1493'),
    edge_color=sv.Color.WHITE,
    radius=16,
    thickness=1,
    pitch=annotated_frame)

sv.plot_image(annotated_frame)

"""## ball tracking"""

from collections import deque
import supervision as sv
from sports.annotators.soccer import draw_pitch, draw_points_on_pitch

SOURCE_VIDEO_PATH = "/content/121364_0.mp4"
BALL_ID = 0
MAXLEN = 5

video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)
frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)

path_raw = []
M = deque(maxlen=MAXLEN)

for frame in tqdm(frame_generator, total=video_info.total_frames):

    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)

    ball_detections = detections[detections.class_id == BALL_ID]
    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
    key_points = sv.KeyPoints.from_inference(result)

    filter = key_points.confidence[0] > 0.5
    frame_reference_points = key_points.xy[0][filter]
    pitch_reference_points = np.array(CONFIG.vertices)[filter]

    transformer = ViewTransformer(
        source=frame_reference_points,
        target=pitch_reference_points
    )
    M.append(transformer.m)
    transformer.m = np.mean(np.array(M), axis=0)

    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)

    path_raw.append(pitch_ball_xy)

path = [
    np.empty((0, 2), dtype=np.float32) if coorinates.shape[0] >= 2 else coorinates
    for coorinates
    in path_raw
]

path = [coorinates.flatten() for coorinates in path]

from sports.annotators.soccer import draw_paths_on_pitch

annotated_frame = draw_pitch(CONFIG)
annotated_frame = draw_paths_on_pitch(
    config=CONFIG,
    paths=[path],
    color=sv.Color.WHITE,
    pitch=annotated_frame)

sv.plot_image(annotated_frame)

from typing import List, Union

def replace_outliers_based_on_distance(
    positions: List[np.ndarray],
    distance_threshold: float
) -> List[np.ndarray]:
    last_valid_position: Union[np.ndarray, None] = None
    cleaned_positions: List[np.ndarray] = []

    for position in positions:
        if len(position) == 0:
            # If the current position is already empty, just add it to the cleaned positions
            cleaned_positions.append(position)
        else:
            if last_valid_position is None:
                # If there's no valid last position, accept the first valid one
                cleaned_positions.append(position)
                last_valid_position = position
            else:
                # Calculate the distance from the last valid position
                distance = np.linalg.norm(position - last_valid_position)
                if distance > distance_threshold:
                    # Replace with empty array if the distance exceeds the threshold
                    cleaned_positions.append(np.array([], dtype=np.float64))
                else:
                    cleaned_positions.append(position)
                    last_valid_position = position

    return cleaned_positions

MAX_DISTANCE_THRESHOLD = 500

path = replace_outliers_based_on_distance(path, MAX_DISTANCE_THRESHOLD)

from sports.annotators.soccer import draw_paths_on_pitch

annotated_frame = draw_pitch(CONFIG)
annotated_frame = draw_paths_on_pitch(
    config=CONFIG,
    paths=[path],
    color=sv.Color.WHITE,
    pitch=annotated_frame)

sv.plot_image(annotated_frame)

"""### objelerin nokta halinde akış videosu"""

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv
import numpy as np
import cv2
from sports.common.view import ViewTransformer
from sports.annotators.soccer import draw_pitch, draw_points_on_pitch
from sports.configs.soccer import SoccerPitchConfiguration
from tqdm import tqdm
import os

# Model ID'leri
ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')
PLAYER_DETECTION_MODEL_ID = "football-players-detection-3zvbc/12"
FIELD_DETECTION_MODEL_ID = "football-field-detection-f07vi/14"

# Modelleri yükle
from inference import get_model
from google.colab import userdata


from sports.common.team import TeamClassifier
import matplotlib.pyplot as plt
import numpy as np
import supervision as sv
from tqdm import tqdm

# Ana kod
import cv2

# Önce matplotlib'i inline moda geçirin (Colab için)
# %matplotlib inline

import supervision as sv


import os

"""###### Adım 1: Videoyu Kaydetmek için Hazırlık"""

# Dosya yolları
SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_11_fraport-tav-antalyaspor_besiktas.mp4"
OUTPUT_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/betul/analysis_output.mp4"

# Çıktı dizinini kontrol et ve oluştur
output_dir = os.path.dirname(OUTPUT_VIDEO_PATH)
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Çıktı dizini oluşturuldu: {output_dir}")

# Nesne ID'leri
BALL_ID = 0
GOALKEEPER_ID = 1
PLAYER_ID = 2
REFEREE_ID = 3

# Çıktı video özellikleri
STRIDE = 5  # Her 5 frame'de bir işlem yapacak (işlem hızı için)
CONFIG = SoccerPitchConfiguration()

# Video bilgilerini al
video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)
fps = video_info.fps / STRIDE  # Çıktı FPS'i
height, width = video_info.height, video_info.width

print("Temel kurulum tamamlandı!")
print(f"Video boyutu: {width}x{height}, FPS: {video_info.fps}")
print(f"Toplam frame sayısı: {video_info.total_frames}")
print(f"Çıktı video boyutu: {width}x{height}, FPS: {fps}")

"""###### Adım 2: Model yüklemelerini kontrol edelim"""

# Model ID'leri
ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')
PLAYER_DETECTION_MODEL_ID = "football-players-detection-3zvbc/12"
FIELD_DETECTION_MODEL_ID = "football-field-detection-f07vi/14"

# Modelleri yükle
from inference import get_model
from google.colab import userdata

print("Modeller yükleniyor...")

try:
    PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)
    print("✅ Oyuncu tespit modeli başarıyla yüklendi")
except Exception as e:
    print(f"❌ Oyuncu tespit modeli yüklenirken hata: {e}")

try:
    FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)
    print("✅ Saha tespit modeli başarıyla yüklendi")
except Exception as e:
    print(f"❌ Saha tespit modeli yüklenirken hata: {e}")

# Test et - bir frame al ve modeli çalıştır
print("\nModel testleri yapılıyor...")

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
test_frame = next(frame_generator)

try:
    player_result = PLAYER_DETECTION_MODEL.infer(test_frame, confidence=0.3)[0]
    detections = sv.Detections.from_inference(player_result)
    print(f"✅ Oyuncu tespit modeli test edildi. {len(detections)} nesne tespit edildi.")
except Exception as e:
    print(f"❌ Oyuncu tespit modeli test edilirken hata: {e}")

try:
    field_result = FIELD_DETECTION_MODEL.infer(test_frame, confidence=0.3)[0]
    key_points = sv.KeyPoints.from_inference(field_result)
    print(f"✅ Saha tespit modeli test edildi. {len(key_points.xy[0])} nokta tespit edildi.")
except Exception as e:
    print(f"❌ Saha tespit modeli test edilirken hata: {e}")

"""###### Adım 3: Team Classifier eğitimini kontrol edelim"""

# Örnek bir frame üzerinde görselleştirme yapalım
def visualize_detections_with_teams(frame, detections, team_predictions):
    """
    Frame üzerinde tespit edilen oyuncuları takımlarına göre farklı renklerle işaretler
    """
    # Takım renklerini belirle (0: takım1-kırmızı, 1: takım2-mavi)
    colors = {
        0: (255, 0, 0),  # Kırmızı - Takım 1
        1: (0, 0, 255),  # Mavi - Takım 2
        -1: (128, 128, 128)  # Gri - Sınıflandırılamayan
    }

    # Görselleştirme için annotator oluştur
    annotated_frame = frame.copy()

    # Her bir tespit için
    for i, xyxy in enumerate(detections.xyxy):
        # Eğer oyuncu tespiti varsa
        if i < len(team_predictions):
            team_id = team_predictions[i]
            color = colors[team_id]

            # Dikdörtgen çiz
            x1, y1, x2, y2 = map(int, xyxy)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # Takım bilgisini yaz
            team_text = f"Takim {team_id+1}"
            cv2.putText(annotated_frame, team_text, (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    return annotated_frame



print("Team Classifier test ediliyor...")
try:
    # Örnek bir sınıflandırıcı oluştur
    team_classifier = TeamClassifier(device="cpu")
    print("✅ Team Classifier sınıfı başarıyla oluşturuldu")
except Exception as e:
    print(f"❌ Team Classifier oluşturulurken hata: {e}")

print("\nTakım sınıflandırıcısı için veri toplanıyor...")
crops = []
all_detections = []  # Tüm tespitleri saklayalım
all_frames = []      # Tespitlerin yapıldığı frameleri saklayalım

frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, stride=30)

try:
    for i, frame in enumerate(tqdm(frame_generator)):
        if i > 100:  # Test için sadece 20 frame'den örnek topla
            break
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)
        players = detections[detections.class_id == PLAYER_ID]

        # Oyuncu tespitlerini ve frameleri sakla
        if len(players) > 0:
            player_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
            crops += player_crops
            all_detections.append(players)
            all_frames.append(frame.copy())

    print(f"✅ {len(crops)} oyuncu görüntüsü toplandı")

    # Team Classifier'ı eğit
    print("\nTakım sınıflandırıcısı eğitiliyor...")
    team_classifier.fit(crops)
    print("✅ Takım sınıflandırıcısı başarıyla eğitildi!")

    # Her bir frame için takım sınıflandırması yap ve görselleştir
    print("\nTespit edilen oyuncular takımlara göre işaretleniyor...")

    for frame_idx, (frame, detections) in enumerate(zip(all_frames, all_detections)):
        # Bu framedeki oyuncu kırpmaları
        frame_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]

        if len(frame_crops) > 0:
            # Takım tahminlerini al
            team_predictions = team_classifier.predict(frame_crops)

            # Görselleştir
            annotated_frame = visualize_detections_with_teams(frame, detections, team_predictions)

            # Sonucu göster
            plt.figure(figsize=(12, 8))
            plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))
            plt.title(f"Frame {frame_idx+1} - Takım Sınıflandırması")
            plt.axis('off')
            plt.show()

            # Sadece bir örnek gösterelim (isteğe bağlı olarak kaldırılabilir)
            if frame_idx == 0:
                print(f"Frame {frame_idx+1} takım tahminleri: {team_predictions}")

    print("✅ Takım tespitleri tamamlandı!")

except Exception as e:
    print(f"❌ İşlem sırasında hata: {e}")

"""###### Adım 4: Yardımcı fonksiyonları tanımlayalım ve test edelim (Team Classifier dahil)"""

# Renk paletini tanımla
COLORS = {
    "team_0": (255, 0, 0),       # Kırmızı - Takım 1
    "team_1": (0, 0, 255),       # Mavi - Takım 2
    "goalkeeper_0": (200, 50, 50),  # Koyu kırmızı - Takım 1 kaleci
    "goalkeeper_1": (50, 50, 200),  # Koyu mavi - Takım 2 kaleci
    "referee": (255, 255, 0),    # Sarı - Hakem
    "ball": (0, 255, 0)          # Yeşil - Top
}

def visualize_detections_with_teams(frame, players, goalkeepers, referees, ball_detections, team_ids, gk_team_ids):
    """
    Frame üzerinde tespit edilen oyuncuları, kalecileri, hakemleri ve topu gösterir
    """
    annotated_frame = frame.copy()

    # Tespit sayılarını yazdır
    print(f"Görselleştiriliyor: {len(players)} oyuncu, {len(goalkeepers)} kaleci, {len(referees)} hakem, {len(ball_detections)} top")

    # Oyuncuları çiz
    for i, xyxy in enumerate(players.xyxy):
        if i < len(team_ids):
            team_id = team_ids[i]
            color = COLORS[f"team_{team_id}"]

            # Dikdörtgen çiz
            x1, y1, x2, y2 = map(int, xyxy)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # Takım ve ID bilgisini yaz
            track_id = players.tracker_id[i] if hasattr(players, 'tracker_id') else i
            team_text = f"T{team_id+1}-ID:{track_id}"
            cv2.putText(annotated_frame, team_text, (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Kalecileri çiz
    for i, xyxy in enumerate(goalkeepers.xyxy):
        if i < len(gk_team_ids):
            team_id = gk_team_ids[i]
            color = COLORS[f"goalkeeper_{team_id}"]

            # Dikdörtgen çiz
            x1, y1, x2, y2 = map(int, xyxy)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # Kaleci ve ID bilgisini yaz
            track_id = goalkeepers.tracker_id[i] if hasattr(goalkeepers, 'tracker_id') else i
            gk_text = f"GK-T{team_id+1}-ID:{track_id}"
            cv2.putText(annotated_frame, gk_text, (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Hakemleri çiz
    for i, xyxy in enumerate(referees.xyxy):
        color = COLORS["referee"]

        # Dikdörtgen çiz
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

        # Hakem ve ID bilgisini yaz
        track_id = referees.tracker_id[i] if hasattr(referees, 'tracker_id') else i
        ref_text = f"REF-ID:{track_id}"
        cv2.putText(annotated_frame, ref_text, (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Topu çiz
    for i, xyxy in enumerate(ball_detections.xyxy):
        color = COLORS["ball"]

        # Dikdörtgen çiz
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

        # Top bilgisini yaz
        ball_text = "BALL"
        cv2.putText(annotated_frame, ball_text, (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    return annotated_frame

def resolve_goalkeepers_team_id(players_detections, goalkeepers_detections, team_ids):
    """Kalecilerin takımlarını, en yakın oyuncuların takımlarını referans alarak belirler."""
    if len(goalkeepers_detections) == 0 or len(players_detections) == 0:
        return np.array([])

    gk_team_ids = []

    for gk_idx in range(len(goalkeepers_detections)):
        gk_xy = goalkeepers_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[gk_idx]

        player_distances = []
        for player_idx in range(len(players_detections)):
            player_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[player_idx]
            distance = np.sqrt(np.sum((gk_xy - player_xy) ** 2))
            team_id = team_ids[player_idx]
            player_distances.append((distance, team_id))

        # En yakın 3 oyuncuyu al
        player_distances.sort(key=lambda x: x[0])
        closest_teams = [team_id for _, team_id in player_distances[:3]]

        # En çok hangi takım yakınsa o takımda
        if len(closest_teams) > 0:
            most_common_team = max(set(closest_teams), key=closest_teams.count)
            gk_team_ids.append(most_common_team)
        else:
            gk_team_ids.append(0)  # Varsayılan olarak 0. takım

    return np.array(gk_team_ids)

# Team Classifier test et
print("Team Classifier test ediliyor...")
try:
    team_classifier = TeamClassifier(device="cpu")  # Eğer GPU varsa "cuda" kullanabilirsiniz
    print("✅ Team Classifier sınıfı başarıyla oluşturuldu")
except Exception as e:
    print(f"❌ Team Classifier oluşturulurken hata: {e}")

# Tracker hazırla
tracker = sv.ByteTrack()
tracker.reset()

# Veri toplama ve eğitim
print("\nTakım sınıflandırıcısı için veri toplanıyor...")
crops = []
frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, stride=30)  # Hızlı tarama için 30 frame atlayarak

try:
    for i, frame in enumerate(tqdm(frame_generator)):
        if i > 20:  # Test için sadece 20 frameden örnek topla
            break
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)
        players = detections[detections.class_id == PLAYER_ID]
        player_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
        crops += player_crops

    print(f"✅ {len(crops)} oyuncu görüntüsü toplandı")

    # Örnek oyuncu görüntülerini görelim
    if len(crops) > 0:
        display_count = min(5, len(crops))
        plt.figure(figsize=(15, 3))
        for i in range(display_count):
            plt.subplot(1, display_count, i+1)
            plt.imshow(cv2.cvtColor(crops[i], cv2.COLOR_BGR2RGB))
            plt.title(f"Oyuncu {i+1}")
            plt.axis('off')
        plt.show()
    else:
        print("⚠️ Hiç oyuncu görüntüsü toplanamadı!")

    # Team Classifier'ı eğit
    print("\nTakım sınıflandırıcısı eğitiliyor...")
    team_classifier.fit(crops)
    print("✅ Takım sınıflandırıcısı başarıyla eğitildi!")

    # Şimdi birkaç frame için tespit ve görselleştirme yapalım
    print("\nFramelerde tespit ve görselleştirme yapılıyor...")

    # Video'yu baştan açalım
    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, stride=5)  # 5 frame atlayarak

    for frame_idx, frame in enumerate(tqdm(frame_generator)):
        if frame_idx > 1000:  # 5 frame işle
            break

        # Tespitleri yap
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)

        # Top tespitlerini ayır
        ball_detections = detections[detections.class_id == BALL_ID]
        all_detections = detections[detections.class_id != BALL_ID]

        # Takip işlemi
        all_detections = tracker.update_with_detections(detections=all_detections)

        # Oyuncu, kaleci ve hakemleri ayır
        goalkeepers = all_detections[all_detections.class_id == GOALKEEPER_ID]
        players = all_detections[all_detections.class_id == PLAYER_ID]
        referees = all_detections[all_detections.class_id == REFEREE_ID]

        print(f"\nFrame {frame_idx+1} tespitleri:")
        print(f"  Toplar: {len(ball_detections)}, Kaleciler: {len(goalkeepers)}, Oyuncular: {len(players)}, Hakemler: {len(referees)}")

        # Takım sınıflandırmaları
        if len(players) > 0:
            players_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
            team_ids = team_classifier.predict(players_crops)

            # Kaleci takım ataması
            gk_team_ids = []
            if len(goalkeepers) > 0:
                gk_team_ids = resolve_goalkeepers_team_id(players, goalkeepers, team_ids)

            # Görselleştir
            annotated_frame = visualize_detections_with_teams(
                frame, players, goalkeepers, referees, ball_detections, team_ids, gk_team_ids
            )

            # Sonucu göster
            plt.figure(figsize=(12, 8))
            plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))
            plt.title(f"Frame {frame_idx+1} - Takım Sınıflandırması")
            plt.axis('off')
            plt.savefig(f"/tmp/frame_{frame_idx+1}.png")  # Dosyaya kaydet
            plt.show()  # Doğrudan göster

            # İstatistikleri yazdır
            if len(team_ids) > 0:
                team_count = np.bincount(team_ids, minlength=2)
                print(f"  Takım sayıları: Takım 1: {team_count[0]}, Takım 2: {team_count[1]}")

            if len(gk_team_ids) > 0:
                print(f"  Kaleci takım ataması: {gk_team_ids}")
        else:
            print("  Bu framede oyuncu tespit edilemedi, görselleştirme yapılamıyor.")

    print("✅ İşlemler tamamlandı!")

except Exception as e:
    import traceback
    print(f"❌ İşlem sırasında hata: {e}")
    print(traceback.format_exc())  # Tam hata izini yazdır

# Renk paletini tanımla
COLORS = {
    "team_0": (255, 0, 0),       # Kırmızı - Takım 1
    "team_1": (0, 0, 255),       # Mavi - Takım 2
    "goalkeeper_0": (200, 50, 50),  # Koyu kırmızı - Takım 1 kaleci
    "goalkeeper_1": (50, 50, 200),  # Koyu mavi - Takım 2 kaleci
    "referee": (255, 255, 0),    # Sarı - Hakem
    "ball": (0, 255, 0)          # Yeşil - Top
}

def visualize_detections_with_teams(frame, players, goalkeepers, referees, ball_detections, team_ids=None, gk_team_ids=None):
    """
    Frame üzerinde tespit edilen oyuncuları, kalecileri, hakemleri ve topu gösterir.
    Oyuncu tespit edilmese bile orijinal frame'i döndürür.
    """
    annotated_frame = frame.copy()

    # Oyuncuları çiz (eğer tespit edilmişse)
    if len(players) > 0 and team_ids is not None:
        for i, xyxy in enumerate(players.xyxy):
            if i < len(team_ids):
                team_id = team_ids[i]
                color = COLORS[f"team_{team_id}"]

                # Dikdörtgen çiz
                x1, y1, x2, y2 = map(int, xyxy)
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

                # Takım ve ID bilgisini yaz
                track_id = players.tracker_id[i] if hasattr(players, 'tracker_id') else i
                team_text = f"T{team_id+1}-ID:{track_id}"
                cv2.putText(annotated_frame, team_text, (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Kalecileri çiz (eğer tespit edilmişse)
    if len(goalkeepers) > 0 and gk_team_ids is not None:
        for i, xyxy in enumerate(goalkeepers.xyxy):
            if i < len(gk_team_ids):
                team_id = gk_team_ids[i]
                color = COLORS[f"goalkeeper_{team_id}"]

                # Dikdörtgen çiz
                x1, y1, x2, y2 = map(int, xyxy)
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

                # Kaleci ve ID bilgisini yaz
                track_id = goalkeepers.tracker_id[i] if hasattr(goalkeepers, 'tracker_id') else i
                gk_text = f"GK-T{team_id+1}-ID:{track_id}"
                cv2.putText(annotated_frame, gk_text, (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Hakemleri çiz
    for i, xyxy in enumerate(referees.xyxy):
        color = COLORS["referee"]

        # Dikdörtgen çiz
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

        # Hakem ve ID bilgisini yaz
        track_id = referees.tracker_id[i] if hasattr(referees, 'tracker_id') else i
        ref_text = f"REF-ID:{track_id}"
        cv2.putText(annotated_frame, ref_text, (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Topu çiz
    for i, xyxy in enumerate(ball_detections.xyxy):
        color = COLORS["ball"]

        # Dikdörtgen çiz
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

        # Top bilgisini yaz
        ball_text = "BALL"
        cv2.putText(annotated_frame, ball_text, (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Tespit bilgisini üst köşeye ekle
    detection_info = f"Toplar: {len(ball_detections)}, Kaleciler: {len(goalkeepers)}, Oyuncular: {len(players)}, Hakemler: {len(referees)}"
    cv2.putText(annotated_frame, detection_info, (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    return annotated_frame

def resolve_goalkeepers_team_id(players_detections, goalkeepers_detections, team_ids):
    """Kalecilerin takımlarını, en yakın oyuncuların takımlarını referans alarak belirler."""
    if len(goalkeepers_detections) == 0 or len(players_detections) == 0:
        return np.array([])

    gk_team_ids = []

    for gk_idx in range(len(goalkeepers_detections)):
        gk_xy = goalkeepers_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[gk_idx]

        player_distances = []
        for player_idx in range(len(players_detections)):
            player_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[player_idx]
            distance = np.sqrt(np.sum((gk_xy - player_xy) ** 2))
            team_id = team_ids[player_idx]
            player_distances.append((distance, team_id))

        # En yakın 3 oyuncuyu al
        player_distances.sort(key=lambda x: x[0])
        closest_teams = [team_id for _, team_id in player_distances[:3]]

        # En çok hangi takım yakınsa o takımda
        if len(closest_teams) > 0:
            most_common_team = max(set(closest_teams), key=closest_teams.count)
            gk_team_ids.append(most_common_team)
        else:
            gk_team_ids.append(0)  # Varsayılan olarak 0. takım

    return np.array(gk_team_ids)

# Ana işlem fonksiyonu
def process_football_video(source_video_path, output_video_path, start_frame=2000, max_frames=1000):
    # ID tanımları
    BALL_ID = 0
    GOALKEEPER_ID = 1
    PLAYER_ID = 2
    REFEREE_ID = 3

    # Team Classifier'ı oluştur
    print("Team Classifier oluşturuluyor...")
    try:
        team_classifier = TeamClassifier(device="cpu")  # GPU varsa "cuda" kullanabilirsiniz
        print("✅ Team Classifier sınıfı başarıyla oluşturuldu")
    except Exception as e:
        print(f"❌ Team Classifier oluşturulurken hata: {e}")
        return

    # Tracker hazırla
    tracker = sv.ByteTrack()
    tracker.reset()

    # Önce eğitim için veri topla
    print("\nTakım sınıflandırıcısı için veri toplanıyor...")
    crops = []

    # Eğitim için video frameleri jeneratörü - başlangıç noktamızdan önceki kısımdan örnekler
    # 10 frame atlayarak start_frame kadar frame içinden örnekler al
    sample_frames = min(start_frame, 500)  # En fazla 500 frame veya start_frame kadarını örnekle
    frame_generator = sv.get_video_frames_generator(source_video_path, stride=max(1, sample_frames // 50))

    # Eğitim için maksimum 50 frame örneği al
    for i, frame in enumerate(tqdm(frame_generator)):
        if i >= 50:  # En fazla 50 örnek
            break
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
        detections = sv.Detections.from_inference(result)
        players = detections[detections.class_id == PLAYER_ID]
        player_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
        crops += player_crops

    print(f"✅ {len(crops)} oyuncu görüntüsü toplandı")

    # Team Classifier'ı eğit
    if len(crops) > 0:
        print("\nTakım sınıflandırıcısı eğitiliyor...")
        team_classifier.fit(crops)
        print("✅ Takım sınıflandırıcısı başarıyla eğitildi!")
    else:
        print("⚠️ Hiç oyuncu tespit edilemedi! Takım sınıflandırıcısı eğitilemedi.")
        return

    # Video bilgilerini al
    print("\nVideo bilgileri alınıyor...")
    cap = cv2.VideoCapture(source_video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Başlangıç frame'ini kontrol et
    if start_frame >= total_frames:
        print(f"⚠️ Başlangıç frame'i ({start_frame}) toplam frame sayısından ({total_frames}) büyük!")
        cap.release()
        return

    # İşlenecek frame sayısını kontrol et
    end_frame = min(start_frame + max_frames, total_frames)
    frames_to_process = end_frame - start_frame

    print(f"Video boyutu: {width}x{height}, FPS: {fps}, Toplam frame: {total_frames}")
    print(f"İşlenecek frameler: {start_frame} - {end_frame-1} (toplam {frames_to_process} frame)")

    # Çıktı videosunu hazırla
    output_dir = os.path.dirname(output_video_path)
    if not os.path.exists(output_dir) and output_dir:
        os.makedirs(output_dir)

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    # İstenen başlangıç frame'ine git (OpenCV kullanarak)
    print(f"\n{start_frame}. frame'e atlanıyor...")
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    # Bu noktadan itibaren frameleri işle
    print("\nBelirtilen frameler işleniyor ve çıktı videosuna yazılıyor...")
    frame_count = 0

    with tqdm(total=frames_to_process) as pbar:
        while cap.isOpened() and frame_count < frames_to_process:
            ret, frame = cap.read()
            if not ret:
                print(f"⚠️ {start_frame + frame_count}. frame okunamadı. Video bitti veya hatalı.")
                break

            # OpenCV BGR formatını RGB'ye çevir
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # Tespitleri yap
            result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
            detections = sv.Detections.from_inference(result)

            # Top tespitlerini ayır
            ball_detections = detections[detections.class_id == BALL_ID]
            all_detections = detections[detections.class_id != BALL_ID]

            # Takip işlemi
            all_detections = tracker.update_with_detections(detections=all_detections)

            # Oyuncu, kaleci ve hakemleri ayır
            goalkeepers = all_detections[all_detections.class_id == GOALKEEPER_ID]
            players = all_detections[all_detections.class_id == PLAYER_ID]
            referees = all_detections[all_detections.class_id == REFEREE_ID]

            # Takım sınıflandırmaları
            team_ids = None
            gk_team_ids = None

            if len(players) > 0:
                players_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
                team_ids = team_classifier.predict(players_crops)

                # Kaleci takım ataması
                if len(goalkeepers) > 0:
                    gk_team_ids = resolve_goalkeepers_team_id(players, goalkeepers, team_ids)

            # Görselleştir
            annotated_frame = visualize_detections_with_teams(
                frame, players, goalkeepers, referees, ball_detections, team_ids, gk_team_ids
            )

            # Frame'i BGR'ye çevir (OpenCV için)
            annotated_frame_bgr = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)

            # Çıktı videosuna yaz
            video_writer.write(annotated_frame_bgr)

            # İlerlemeyi güncelle
            frame_count += 1
            pbar.update(1)

            # Her 100 framede bir ilerleme raporu ver
            if frame_count % 100 == 0:
                current_frame = start_frame + frame_count
                print(f"İlerleme: {frame_count}/{frames_to_process} frame işlendi (Frame #{current_frame})")

    # Kaynakları serbest bırak
    cap.release()
    video_writer.release()

    print(f"\n✅ İşlenmiş video kaydedildi: {output_video_path}")
    print(f"Toplam {frame_count} frame işlendi.")

# Fonksiyonu çalıştır
if __name__ == "__main__":
    SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_10_adana-demirspor_ittifak-holding-konyaspor.mp4"
    OUTPUT_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/analysis_output_2000_3000.mp4"

    # 2000. frameden başlayarak 1000 frame işle
    process_football_video(SOURCE_VIDEO_PATH, OUTPUT_VIDEO_PATH, start_frame=2000, max_frames=1000)

"""###### Adım 5: Saha tespiti ve çizimi test edelim"""

try:
    print("Saha tespiti ve çizimi test ediliyor...")

    # Pitch görünümü çiz
    pitch_view = draw_pitch(CONFIG)

    # 3:51 zaman noktasındaki frame'i al
    import cv2
    cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)
    fps = cap.get(cv2.CAP_PROP_FPS)
    target_time = 3 * 60 + 51  # 3:51 (dakika:saniye)
    target_frame = int(target_time * fps)

    # İstenen frame'e atla
    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
    ret, test_frame = cap.read()

    if not ret:
        raise Exception("3:51 zaman noktasındaki frame okunamadı")

    # Saha köşe noktalarını tespit et
    field_result = FIELD_DETECTION_MODEL.infer(test_frame, confidence=0.3)[0]
    key_points = sv.KeyPoints.from_inference(field_result)

    # Güvenilir köşe noktalarını filtrele
    filter = key_points.confidence[0] > 0.5
    print(f"   Tespit edilen güvenilir köşe noktaları: {np.sum(filter)}/10")

    if np.sum(filter) >= 4:  # En az 4 köşe noktası gerekli
        frame_reference_points = key_points.xy[0][filter]
        pitch_reference_points = np.array(CONFIG.vertices)[filter]

        # Görüş dönüştürücüsünü oluştur
        transformer = ViewTransformer(
            source=frame_reference_points,
            target=pitch_reference_points
        )

        # Test için bir nokta dönüştür
        height, width = test_frame.shape[:2]  # Frame boyutlarını doğru şekilde al
        test_point = np.array([[width/2, height/2]])  # Ekranın ortası
        transformed_point = transformer.transform_points(points=test_point)

        print(f"✅ Saha tespiti ve dönüşüm başarılı")
        print(f"   Test noktası dönüşümü: Ekran ({width/2}, {height/2}) -> Saha ({transformed_point[0][0]:.1f}, {transformed_point[0][1]:.1f})")

        # Görselleştirme
        plt.figure(figsize=(15, 5))

        # Orijinal frame ve tespit edilen köşe noktaları
        plt.subplot(1, 3, 1)
        vertex_annotator = sv.VertexAnnotator(color=sv.Color.from_hex('#FF1493'), radius=8)
        frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])
        annotated_frame = test_frame.copy()
        annotated_frame = vertex_annotator.annotate(scene=annotated_frame, key_points=frame_reference_key_points)
        plt.imshow(annotated_frame)
        plt.title("Tespit Edilen Köşe Noktaları")
        plt.axis('off')

        # Saha görünümü
        plt.subplot(1, 3, 2)
        plt.imshow(pitch_view)
        plt.title("Saha Görünümü")
        plt.axis('off')

        # Dönüştürülmüş saha çizimi
        plt.subplot(1, 3, 3)
        # Tüm pitch köşe noktalarını dönüştür
        pitch_all_points = np.array(CONFIG.vertices)
        try:
            frame_all_points = transformer.transform_points(points=pitch_all_points, source_to_target=False)

            # Dönüştürülmüş köşe noktalarını çiz
            edge_annotator = sv.EdgeAnnotator(color=sv.Color.from_hex('#00BFFF'), thickness=2, edges=CONFIG.edges)
            frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])
            annotated_frame2 = test_frame.copy()
            annotated_frame2 = edge_annotator.annotate(scene=annotated_frame2, key_points=frame_all_key_points)
            plt.imshow(annotated_frame2)
            plt.title("Sahayı Frame'e Yansıtma")
        except Exception as e:
            plt.text(0.5, 0.5, f"Dönüşüm hatası: {e}", ha='center', va='center')
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    else:
        print("❌ Yeterli köşe noktası tespit edilemedi. Farklı bir frame deneyin.")

    # İşimiz bittiğinde video nesnesini kapat
    cap.release()

except Exception as e:
    print(f"❌ Saha tespiti test edilirken hata: {e}")

"""###### Adım 6: Tüm tespit işlemlerini ve saha yansıtmayı tek bir frame'de test edelim"""

#source pathleri??

try:
    print("Tam iş akışı testi yapılıyor...")

    # Tracker oluştur ve sıfırla
    tracker = sv.ByteTrack()
    tracker.reset()

    # 3:51 zaman noktasındaki frame'i al
    import cv2
    cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)
    fps = cap.get(cv2.CAP_PROP_FPS)
    target_time = 3 * 60 + 51  # 3:51 (dakika:saniye)
    target_frame = int(target_time * fps)

    # İstenen frame'e atla
    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
    ret, test_frame = cap.read()

    if not ret:
        raise Exception("3:51 zaman noktasındaki frame okunamadı")

    # BGR'den RGB'ye çevir (görselleştirme için)
    test_frame_rgb = cv2.cvtColor(test_frame, cv2.COLOR_BGR2RGB)

    # 1. Oyuncu, kaleci, top ve hakem tespiti
    result = PLAYER_DETECTION_MODEL.infer(test_frame_rgb, confidence=0.3)[0]
    detections = sv.Detections.from_inference(result)

    # Top tespitlerini ayır
    ball_detections = detections[detections.class_id == BALL_ID]
    if len(ball_detections) > 0:
        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

    # Diğer tespitleri işle
    all_detections = detections[detections.class_id != BALL_ID]
    if len(all_detections) > 0:
        all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
        all_detections = tracker.update_with_detections(detections=all_detections)

    # Oyuncu, kaleci ve hakemleri ayır
    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]
    players_detections = all_detections[all_detections.class_id == PLAYER_ID]
    referees_detections = all_detections[all_detections.class_id == REFEREE_ID]

    # 2. Takım tanımlama (TeamClassifier kullanarak)
    if len(players_detections) > 0:
        # Sports reposundan TeamClassifier'ı içe aktar
        from sports.common.team import TeamClassifier

        # Önce eğitim verileri topla
        print("Eğitim verileri için daha fazla oyuncu örneği toplanıyor...")
        training_crops = []
        # Videonun farklı bölümlerinden örnekler toplayalım
        temp_frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, stride=30)
        for i, frame in enumerate(temp_frame_generator):
            if i > 30:  # 30 farklı frame'den veri topla
                break
            temp_result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]
            temp_detections = sv.Detections.from_inference(temp_result)
            temp_players = temp_detections[temp_detections.class_id == PLAYER_ID]
            temp_crops = [sv.crop_image(frame, xyxy) for xyxy in temp_players.xyxy]
            training_crops.extend(temp_crops)

        # Mevcut frame'deki oyuncuları da ekle
        players_crops = [sv.crop_image(test_frame_rgb, xyxy) for xyxy in players_detections.xyxy]
        all_crops = training_crops + players_crops

        if len(all_crops) > 0:
            print(f"TeamClassifier, {len(all_crops)} oyuncu görüntüsü ile eğitiliyor...")
            team_classifier = TeamClassifier(device="cpu")  # GPU varsa "cuda" olabilir
            team_classifier.fit(all_crops)

            # Oyuncuları sınıflandır
            players_detections.class_id = team_classifier.predict(players_crops)
            print(f"Oyuncular {np.sum(players_detections.class_id == 0)} - {np.sum(players_detections.class_id == 1)} olarak sınıflandırıldı.")

    # Kaleci takım ataması
    if len(goalkeepers_detections) > 0 and len(players_detections) > 0:
        # Kaleci takım atama fonksiyonu
        def resolve_goalkeepers_team_id(players_detections, goalkeepers_detections):
            """Kalecilerin takımlarını, en yakın oyuncuların takımlarını referans alarak belirler."""
            if len(goalkeepers_detections) == 0 or len(players_detections) == 0:
                return np.array([])

            gk_team_ids = []

            for gk_idx in range(len(goalkeepers_detections)):
                gk_xy = goalkeepers_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[gk_idx]

                player_distances = []
                for player_idx in range(len(players_detections)):
                    player_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[player_idx]
                    distance = np.sqrt(np.sum((gk_xy - player_xy) ** 2))
                    player_distances.append((distance, players_detections.class_id[player_idx]))

                # En yakın 3 oyuncuyu al
                player_distances.sort(key=lambda x: x[0])
                closest_teams = [team_id for _, team_id in player_distances[:3]]

                # En çok hangi takım yakınsa o takımda
                if len(closest_teams) > 0:
                    most_common_team = max(set(closest_teams), key=closest_teams.count)
                    gk_team_ids.append(most_common_team)
                else:
                    gk_team_ids.append(0)  # Varsayılan olarak 0. takım

            return np.array(gk_team_ids)

        goalkeepers_detections.class_id = resolve_goalkeepers_team_id(
            players_detections, goalkeepers_detections)
        print(f"Kaleciler takımlara atandı: {goalkeepers_detections.class_id}")

    if len(referees_detections) > 0:
        # Hakemleri -1 olarak işaretle (farklı renkle göstermek için)
        referees_detections.class_id = np.zeros(len(referees_detections), dtype=int) - 1

    # 3. Saha köşe noktalarını tespit et
    try:
        field_result = FIELD_DETECTION_MODEL.infer(test_frame_rgb, confidence=0.3)[0]
        key_points = sv.KeyPoints.from_inference(field_result)

        # Güvenilir köşe noktalarını filtrele
        filter = key_points.confidence[0] > 0.5
        print(f"Tespit edilen köşe noktaları: {np.sum(filter)}/10")
    except Exception as e:
        print(f"Saha tespitinde hata: {e}")
        filter = np.array([False] * 10)  # Varsayılan filtre (hiçbir nokta güvenilir değil)
        key_points = None

    # Yeterli köşe noktası var mı kontrol et
    if np.sum(filter) >= 4:  # En az 4 köşe noktası gerekli
        frame_reference_points = key_points.xy[0][filter]
        pitch_reference_points = np.array(CONFIG.vertices)[filter]

        # Görüş dönüştürücüsünü oluştur
        transformer = ViewTransformer(
            source=frame_reference_points,
            target=pitch_reference_points
        )

        # 4. Birleşik tespitleri oluştur
        all_game_detections = sv.Detections.merge([players_detections, goalkeepers_detections])

        # 5. Görselleştirme - Ana görseller
        plt.figure(figsize=(18, 10))

        # Orijinal frame ve tespitler
        plt.subplot(1, 2, 1)
        ellipse_annotator = sv.EllipseAnnotator(
            color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']), thickness=2)
        triangle_annotator = sv.TriangleAnnotator(
            color=sv.Color.from_hex('#FFD700'), base=20, height=17)

        annotated_frame = test_frame_rgb.copy()
        if len(all_game_detections) > 0:
            annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_game_detections)
        if len(ball_detections) > 0:
            annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)
        if len(referees_detections) > 0:
            # Hakemleri sarı renkle işaretle
            referee_annotator = sv.EllipseAnnotator(
                color=sv.ColorPalette.from_hex(['#FFD700']), thickness=2)
            annotated_frame = referee_annotator.annotate(scene=annotated_frame, detections=referees_detections)

        plt.imshow(annotated_frame)
        plt.title("Tespit Edilen Nesneler")
        plt.axis('off')

        # Saha görünümü
        plt.subplot(1, 2, 2)
        pitch_view = draw_pitch(CONFIG)

        # Top varsa yansıt
        if len(ball_detections) > 0:
            frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
            pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)

            # Topları çiz
            pitch_view = draw_points_on_pitch(
                config=CONFIG,
                xy=pitch_ball_xy,
                face_color=sv.Color.from_hex('#FF00FF'),  # Mor
                edge_color=sv.Color.BLACK,
                radius=10,
                pitch=pitch_view
            )

        # Oyuncuları yansıt
        if len(all_game_detections) > 0:
            players_xy = all_game_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
            pitch_players_xy = transformer.transform_points(points=players_xy)

            # Takım 1 oyuncuları
            team1_mask = all_game_detections.class_id == 0
            if np.any(team1_mask):
                pitch_view = draw_points_on_pitch(
                    config=CONFIG,
                    xy=pitch_players_xy[team1_mask],
                    face_color=sv.Color.from_hex('#FFFF00'),  # Sarı
                    edge_color=sv.Color.BLACK,
                    radius=16,
                    pitch=pitch_view
                )

            # Takım 2 oyuncuları
            team2_mask = all_game_detections.class_id == 1
            if np.any(team2_mask):
                pitch_view = draw_points_on_pitch(
                    config=CONFIG,
                    xy=pitch_players_xy[team2_mask],
                    face_color=sv.Color.from_hex('#00BFFF'),  # Mavi
                    edge_color=sv.Color.BLACK,
                    radius=16,
                    pitch=pitch_view
                )

        # Hakemleri yansıt
        if len(referees_detections) > 0:
            referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
            pitch_referees_xy = transformer.transform_points(points=referees_xy)

            pitch_view = draw_points_on_pitch(
                config=CONFIG,
                xy=pitch_referees_xy,
                face_color=sv.Color.from_hex('#FF69B4'),  # Pembe
                edge_color=sv.Color.BLACK,
                radius=16,
                pitch=pitch_view
            )

        plt.imshow(pitch_view)
        plt.title("Saha Üzerinde Oyuncular ve Top")
        plt.axis('off')

        plt.tight_layout()
        plt.show()

        # 6. İkinci figür - Takım örnekleri ve bilgiler
        if len(players_crops) > 0:
            plt.figure(figsize=(12, 8))

            # Sol panel: Takım örnekleri
            plt.subplot(1, 2, 1)
            team1_crops = [crop for i, crop in enumerate(players_crops) if players_detections.class_id[i] == 0]
            team2_crops = [crop for i, crop in enumerate(players_crops) if players_detections.class_id[i] == 1]

            plt.axis('off')
            plt.title("Takım Örnekleri", fontsize=14)

            # Takım 1 örnekleri
            if len(team1_crops) > 0:
                plt.figure(figsize=(6, 4))
                plt.suptitle("Takım 1", fontsize=16)
                for i, crop in enumerate(team1_crops[:3]):  # Sadece ilk 3'ü göster
                    plt.subplot(1, 3, i+1)
                    plt.imshow(crop)
                    plt.axis('off')
                plt.tight_layout()
                plt.show()

            # Takım 2 örnekleri
            if len(team2_crops) > 0:
                plt.figure(figsize=(6, 4))
                plt.suptitle("Takım 2", fontsize=16)
                for i, crop in enumerate(team2_crops[:3]):  # Sadece ilk 3'ü göster
                    plt.subplot(1, 3, i+1)
                    plt.imshow(crop)
                    plt.axis('off')
                plt.tight_layout()
                plt.show()

            # İstatistikler
            plt.figure(figsize=(8, 6))
            plt.axis('off')
            info_text = f"""
            Frame bilgileri:

            - Top sayısı: {len(ball_detections)}
            - Oyuncu sayısı: {len(players_detections)}
              * Takım 1 (Sarı): {np.sum(players_detections.class_id == 0)} oyuncu
              * Takım 2 (Mavi): {np.sum(players_detections.class_id == 1)} oyuncu
            - Kaleci sayısı: {len(goalkeepers_detections)}
              * Takım 1 (Sarı): {np.sum(goalkeepers_detections.class_id == 0)} kaleci
              * Takım 2 (Mavi): {np.sum(goalkeepers_detections.class_id == 1)} kaleci
            - Hakem sayısı: {len(referees_detections)}
            - Tespit edilen köşe noktaları: {np.sum(filter)}/10
            """
            plt.text(0.1, 0.5, info_text, va='center', fontsize=12)
            plt.title("İstatistikler", fontsize=14)
            plt.tight_layout()
            plt.show()

        # İşimiz bittiğinde video nesnesini kapat
        cap.release()

        print("✅ Tam iş akışı testi başarılı!")
    else:
        print("❌ Yeterli köşe noktası tespit edilemedi. Farklı bir frame deneyin.")
        cap.release()
except Exception as e:
    import traceback
    print(f"❌ Tam iş akışı testi sırasında hata: {e}")
    print(traceback.format_exc())  # Tam hata izini yazdır
    if 'cap' in locals():
        cap.release()

"""###### Adım 7: Video oluşturma 2D"""

import os
import numpy as np
import supervision as sv
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from sports.common.team import TeamClassifier
from sports.common.view import ViewTransformer
from sports.annotators.soccer import draw_pitch, draw_points_on_pitch
from sports.configs.soccer import SoccerPitchConfiguration

# 4000-6000 frame aralığı için parametreler
def process_soccer_video(
    source_video_path=SOURCE_VIDEO_PATH,
    output_video_path=OUTPUT_VIDEO_PATH,
    start_frame=4000,    # 4000. frame'den başla
    max_frames=2000,     # 2000 frame işle (4000'den başlayıp 6000'e kadar)
    confidence_threshold=0.3,
    training_stride=30,  # Eğitim için her 30 frame'de bir örnek al
    training_frames=50   # 50 frame'den veri topla
):
    """
    Futbol videosunu işleyerek oyuncuları, kalecileri ve hakemler tespit eder,
    takım sınıflandırması yapar ve sonuçları bir video olarak kaydeder.

    Args:
        source_video_path: Kaynak video dosyasının yolu
        output_video_path: Çıktı video dosyasının yolu
        start_frame: Başlangıç frame numarası
        max_frames: İşlenecek maksimum frame sayısı (None ise tüm video)
        confidence_threshold: Nesne tespiti için minimum güven eşiği
        training_stride: Eğitim verileri toplarken atlanan frame sayısı
        training_frames: Eğitim için kullanılacak frame sayısı
    """

    print("Futbol maçı analizi başlatılıyor...")

    # Nesne ID'leri
    BALL_ID = 0
    GOALKEEPER_ID = 1
    PLAYER_ID = 2
    REFEREE_ID = 3

    # Saha konfigürasyonu
    CONFIG = SoccerPitchConfiguration()

    # Video bilgilerini al
    print("Video bilgileri alınıyor...")
    cap = cv2.VideoCapture(source_video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # İşlenecek frame sayısını belirle
    if max_frames is None:
        max_frames = total_frames - start_frame
    end_frame = min(start_frame + max_frames, total_frames)
    frames_to_process = end_frame - start_frame

    print(f"Video özellikleri: {width}x{height}, {fps} FPS, {total_frames} toplam frame")
    print(f"İşlenecek frame aralığı: {start_frame} - {end_frame-1} ({frames_to_process} frame)")

    # Çıktı dizinini oluştur
    output_dir = os.path.dirname(output_video_path)
    if not os.path.exists(output_dir) and output_dir:
        os.makedirs(output_dir)

    # Eğitim verileri toplama
    print("\n1. Takım sınıflandırıcısı için eğitim verileri toplanıyor...")
    training_crops = []

    # Eğitim verileri için frame jeneratörü
    training_frame_generator = sv.get_video_frames_generator(source_video_path, stride=training_stride)

    for i, frame in enumerate(tqdm(training_frame_generator, desc="Eğitim verileri toplama")):
        if i >= training_frames:
            break

        # Nesneleri tespit et
        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=confidence_threshold)[0]
        detections = sv.Detections.from_inference(result)
        players = detections[detections.class_id == PLAYER_ID]

        # Oyuncu görüntülerini topla
        if len(players) > 0:
            player_crops = [sv.crop_image(frame, xyxy) for xyxy in players.xyxy]
            training_crops.extend(player_crops)

    if len(training_crops) == 0:
        print("⚠️ Hiç eğitim verisi toplanamadı! Lütfen video içeriğini kontrol edin.")
        return

    print(f"✅ {len(training_crops)} oyuncu görüntüsü toplandı.")

    # TeamClassifier'ı eğit
    print("\n2. TeamClassifier eğitiliyor...")
    team_classifier = TeamClassifier(device="cpu")  # GPU varsa "cuda" kullanabilirsiniz
    team_classifier.fit(training_crops)
    print("✅ TeamClassifier başarıyla eğitildi!")

    # Kaleci takım ataması için fonksiyon
    def resolve_goalkeepers_team_id(players_detections, goalkeepers_detections):
        """Kalecilerin takımlarını, en yakın oyuncuların takımlarını referans alarak belirler."""
        if len(goalkeepers_detections) == 0 or len(players_detections) == 0:
            return np.array([])

        gk_team_ids = []

        for gk_idx in range(len(goalkeepers_detections)):
            gk_xy = goalkeepers_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[gk_idx]

            player_distances = []
            for player_idx in range(len(players_detections)):
                player_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[player_idx]
                distance = np.sqrt(np.sum((gk_xy - player_xy) ** 2))
                player_distances.append((distance, players_detections.class_id[player_idx]))

            # En yakın 3 oyuncuyu al
            player_distances.sort(key=lambda x: x[0])

            # Düzeltilmiş kod
            if len(player_distances) >= 3:
                closest_teams = [team_id for _, team_id in player_distances[:3]]
            else:
                closest_teams = [team_id for _, team_id in player_distances]

            # En çok hangi takım yakınsa o takımda
            if len(closest_teams) > 0:
                most_common_team = max(set(closest_teams), key=closest_teams.count)
                gk_team_ids.append(most_common_team)
            else:
                gk_team_ids.append(0)  # Varsayılan olarak 0. takım

        return np.array(gk_team_ids)

    # Tracker başlat
    tracker = sv.ByteTrack()
    tracker.reset()

    # Görselleştirme için annotatorler
    ellipse_annotator = sv.EllipseAnnotator(
        color=sv.ColorPalette.from_hex(['#FFFF00', '#00BFFF', '#FF69B4']),  # Sarı, Mavi, Pembe
        thickness=2
    )
    triangle_annotator = sv.TriangleAnnotator(
        color=sv.Color.from_hex('#FF00FF'),  # Mor
        base=20,
        height=17
    )

    # Çıktı video yazıcısını oluştur
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(
        output_video_path,
        fourcc,
        fps,
        (width*2, height)  # Yan yana iki görüntü
    )

    # İstenen başlangıç frame'ine git
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    # Tüm videoyu işle
    print(f"\n3. Video işleniyor ve {output_video_path} yoluna kaydediliyor...")

    with tqdm(total=frames_to_process, desc="Video işleme") as pbar:
        frame_count = 0

        while cap.isOpened() and frame_count < frames_to_process:
            ret, frame = cap.read()
            if not ret:
                break

            # BGR -> RGB dönüşümü
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # 1. Nesneleri tespit et
            result = PLAYER_DETECTION_MODEL.infer(frame_rgb, confidence=confidence_threshold)[0]
            detections = sv.Detections.from_inference(result)

            # Top tespitlerini ayır
            ball_detections = detections[detections.class_id == BALL_ID]
            if len(ball_detections) > 0:
                ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)

            # Diğer nesneleri işle
            all_detections = detections[detections.class_id != BALL_ID]
            if len(all_detections) > 0:
                all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)
                all_detections = tracker.update_with_detections(detections=all_detections)

            # Oyuncu, kaleci ve hakemleri ayır
            goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]
            players_detections = all_detections[all_detections.class_id == PLAYER_ID]
            referees_detections = all_detections[all_detections.class_id == REFEREE_ID]

            # 2. Takım sınıflandırması
            if len(players_detections) > 0:
                players_crops = [sv.crop_image(frame_rgb, xyxy) for xyxy in players_detections.xyxy]
                players_detections.class_id = team_classifier.predict(players_crops)

            # 3. Kaleci takım ataması
            if len(goalkeepers_detections) > 0 and len(players_detections) > 0:
                goalkeepers_detections.class_id = resolve_goalkeepers_team_id(
                    players_detections, goalkeepers_detections)

            # 4. Hakemleri -1 olarak işaretle
            if len(referees_detections) > 0:
                referees_detections.class_id = np.full(len(referees_detections), 2)  # 2 = hakem için

            # 5. Saha köşe noktalarını tespit et
            try:
                field_result = FIELD_DETECTION_MODEL.infer(frame_rgb, confidence=confidence_threshold)[0]
                key_points = sv.KeyPoints.from_inference(field_result)
                filter = key_points.confidence[0] > 0.5
            except Exception as e:
                if frame_count == 0:  # Sadece ilk hatayı göster
                    print(f"Saha tespitinde hata: {e}")
                filter = np.array([False] * 10)

            # 6. Görselleştirme
            annotated_frame = frame_rgb.copy()

            # Tüm oyuncuları ve kalecileri birleştir
            all_game_detections = sv.Detections.merge([players_detections, goalkeepers_detections])

            # Anotasyonları uygula
            if len(all_game_detections) > 0:
                annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_game_detections)
            if len(ball_detections) > 0:
                annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)
            if len(referees_detections) > 0:
                # Hakem anotasyonu
                referee_annotator = sv.EllipseAnnotator(color=sv.ColorPalette.from_hex(['#FF69B4']), thickness=2)
                annotated_frame = referee_annotator.annotate(scene=annotated_frame, detections=referees_detections)

            # Saha görüntüsü oluştur
            pitch_view = draw_pitch(CONFIG)

            # Eğer yeterli köşe noktası varsa, oyuncuları ve topu saha üzerine yansıt
            if np.sum(filter) >= 4:
                frame_reference_points = key_points.xy[0][filter]
                pitch_reference_points = np.array(CONFIG.vertices)[filter]

                transformer = ViewTransformer(
                    source=frame_reference_points,
                    target=pitch_reference_points
                )

                # Top varsa saha üzerine yansıt
                if len(ball_detections) > 0:
                    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
                    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)

                    pitch_view = draw_points_on_pitch(
                        config=CONFIG,
                        xy=pitch_ball_xy,
                        face_color=sv.Color.from_hex('#FF00FF'),  # Mor
                        edge_color=sv.Color.BLACK,
                        radius=10,
                        pitch=pitch_view
                    )

                # Oyuncuları saha üzerine yansıt
                if len(all_game_detections) > 0:
                    players_xy = all_game_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
                    pitch_players_xy = transformer.transform_points(points=players_xy)

                    # Takım 1 (Sarı)
                    team1_mask = all_game_detections.class_id == 0
                    if np.any(team1_mask):
                        pitch_view = draw_points_on_pitch(
                            config=CONFIG,
                            xy=pitch_players_xy[team1_mask],
                            face_color=sv.Color.from_hex('#FFFF00'),  # Sarı
                            edge_color=sv.Color.BLACK,
                            radius=16,
                            pitch=pitch_view
                        )

                    # Takım 2 (Mavi)
                    team2_mask = all_game_detections.class_id == 1
                    if np.any(team2_mask):
                        pitch_view = draw_points_on_pitch(
                            config=CONFIG,
                            xy=pitch_players_xy[team2_mask],
                            face_color=sv.Color.from_hex('#00BFFF'),  # Mavi
                            edge_color=sv.Color.BLACK,
                            radius=16,
                            pitch=pitch_view
                        )

                # Hakemleri saha üzerine yansıt
                if len(referees_detections) > 0:
                    referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)
                    pitch_referees_xy = transformer.transform_points(points=referees_xy)

                    pitch_view = draw_points_on_pitch(
                        config=CONFIG,
                        xy=pitch_referees_xy,
                        face_color=sv.Color.from_hex('#FF69B4'),  # Pembe
                        edge_color=sv.Color.BLACK,
                        radius=16,
                        pitch=pitch_view
                    )

            # İstatistikleri ekle
            team1_count = np.sum(players_detections.class_id == 0) if len(players_detections) > 0 else 0
            team2_count = np.sum(players_detections.class_id == 1) if len(players_detections) > 0 else 0

            cv2.putText(
                annotated_frame,
                f"Takım 1 (Sarı): {team1_count}, Takım 2 (Mavi): {team2_count}, Top: {len(ball_detections)}, Hakem: {len(referees_detections)}",
                (10, 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2
            )

            # Köşe noktası sayısını ekle
            cv2.putText(
                annotated_frame,
                f"Köşe noktaları: {np.sum(filter)}/10",
                (10, 50),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2
            )

            # Frame numarasını ekle
            current_frame = start_frame + frame_count
            cv2.putText(
                annotated_frame,
                f"Frame: {current_frame}/{total_frames}",
                (10, height - 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2
            )

            # Görüntüleri yan yana birleştir
            # pitch_view'ı annotated_frame ile aynı boyuta getir
            pitch_view_resized = cv2.resize(pitch_view, (width, height))

            # RGB'den BGR'ye çevir (OpenCV için)
            annotated_frame_bgr = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
            pitch_view_bgr = cv2.cvtColor(pitch_view_resized, cv2.COLOR_RGB2BGR)

            # İki görüntüyü yan yana birleştir
            combined_frame = np.hstack((annotated_frame_bgr, pitch_view_bgr))

            # Videoyu kaydet
            out.write(combined_frame)

            # İlerlemeyi güncelle
            frame_count += 1
            pbar.update(1)

    # Kaynakları serbest bırak
    cap.release()
    out.release()

    print(f"\n✅ İşlem tamamlandı! Çıktı videosu: {output_video_path}")
    print(f"Toplam {frame_count} frame işlendi.")

# Kodu çalıştır
if __name__ == "__main__":
    SOURCE_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/downloads/2023-2024/2023-2024_11_fraport-tav-antalyaspor_besiktas.mp4"
    OUTPUT_VIDEO_PATH = "/content/drive/MyDrive/videos_bein_sports/betul/analysis_team_classifier_4000frames.mp4"

    # İlk 4000 frame için parametreler
    process_soccer_video(
        source_video_path=SOURCE_VIDEO_PATH,
        output_video_path=OUTPUT_VIDEO_PATH,
        start_frame=0,      # 0. frame'den başla
        max_frames=4000,    # İlk 4000 frame'i işle MAÇ TAMAMI İÇİN BU KISIM DEĞİŞECEK
        confidence_threshold=0.3,
        training_stride=30, # Eğitim için her 30 frame'de bir örnek al
        training_frames=50  # 50 frame'den veri topla
    )